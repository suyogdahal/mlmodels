{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist mlmodels .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2lSFlDrdbWvY",
        "PoU7BLfdNga4",
        "Rcb8FlWosohQ",
        "liSTPBQVTKmn",
        "ZSLJnpclsAFI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOlpSCdoIazS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUyCIBHtt2OU",
        "colab_type": "text"
      },
      "source": [
        "# Download and configuration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PkVKHw5sPYz",
        "colab_type": "code",
        "outputId": "5eab7d58-5a12-4ecb-c7d5-3025b3872a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/ahmed3bbas/mlmodels.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mlmodels'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 12530 (delta 18), reused 17 (delta 8), pack-reused 12497\u001b[K\n",
            "Receiving objects: 100% (12530/12530), 537.21 MiB | 32.73 MiB/s, done.\n",
            "Resolving deltas: 100% (7453/7453), done.\n",
            "Checking out files: 100% (2891/2891), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zECDgmq36Ild",
        "colab_type": "code",
        "outputId": "418696b8-007e-4d61-d27b-eda9354ee338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        " !pip install numpy==1.17.5 pillow==6.2.1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.17.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/c9/69096779fd29bf3066e24124e1c88213e40bf9d2eab4786d21948a37c40b/numpy-1.17.5-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 5.8MB/s \n",
            "\u001b[?25hCollecting pillow==6.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5c/0e94e689de2476c4c5e644a3bd223a1c1b9e2bdb7c510191750be74fa786/Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 21.3MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pillow\n",
            "  Found existing installation: numpy 1.18.2\n",
            "    Uninstalling numpy-1.18.2:\n",
            "      Successfully uninstalled numpy-1.18.2\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed numpy-1.17.5 pillow-6.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4nK9Lresrmi",
        "colab_type": "code",
        "outputId": "9a3606ad-c68b-480b-ed4c-b3a0aba0e7af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd mlmodels/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mlmodels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnqAMhVWyj0d",
        "colab_type": "code",
        "outputId": "4f37379f-d6e0-4059-ae71-2c5561297fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!git checkout vision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Branch 'vision' set up to track remote branch 'vision' from 'origin'.\n",
            "Switched to a new branch 'vision'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "067C8CYnvbwd",
        "colab_type": "code",
        "outputId": "877087ea-de66-436e-aab5-9edeec33ad75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install  git+https://github.com/arita37/mlmodels.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/arita37/mlmodels.git\n",
            "  Cloning https://github.com/arita37/mlmodels.git to /tmp/pip-req-build-fi68enuj\n",
            "  Running command git clone -q https://github.com/arita37/mlmodels.git /tmp/pip-req-build-fi68enuj\n",
            "Requirement already satisfied (use --upgrade to upgrade): mlmodels==0.32.1 from git+https://github.com/arita37/mlmodels.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torch==1.2.0 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (1.2.0)\n",
            "Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (1.15.2)\n",
            "Requirement already satisfied: keras<2.4.0 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (2.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (1.18.2)\n",
            "Requirement already satisfied: optuna<1.2.0 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (1.1.0)\n",
            "Requirement already satisfied: pandas<1.0 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (0.25.3)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (0.21.2)\n",
            "Requirement already satisfied: numexpr>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (2.7.1)\n",
            "Requirement already satisfied: sqlalchemy<=1.3.13 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (1.3.13)\n",
            "Requirement already satisfied: boto3==1.9.187 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (1.9.187)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (0.10.0)\n",
            "Requirement already satisfied: setuptools==45.2.0 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (45.2.0)\n",
            "Requirement already satisfied: python-dateutil==2.8.0 in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (2.8.0)\n",
            "Requirement already satisfied: cli_code in /usr/local/lib/python3.6/dist-packages (from mlmodels==0.32.1) (28.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (3.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (1.15.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (0.34.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2->mlmodels==0.32.1) (1.12.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras<2.4.0->mlmodels==0.32.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<2.4.0->mlmodels==0.32.1) (3.13)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from optuna<1.2.0->mlmodels==0.32.1) (1.4.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna<1.2.0->mlmodels==0.32.1) (4.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna<1.2.0->mlmodels==0.32.1) (0.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna<1.2.0->mlmodels==0.32.1) (4.45.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.6/dist-packages (from optuna<1.2.0->mlmodels==0.32.1) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas<1.0->mlmodels==0.32.1) (2018.9)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.187 in /usr/local/lib/python3.6/dist-packages (from boto3==1.9.187->mlmodels==0.32.1) (1.12.253)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3==1.9.187->mlmodels==0.32.1) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3==1.9.187->mlmodels==0.32.1) (0.9.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->mlmodels==0.32.1) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2->mlmodels==0.32.1) (1.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna<1.2.0->mlmodels==0.32.1) (1.1.2)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna<1.2.0->mlmodels==0.32.1) (1.0.4)\n",
            "Requirement already satisfied: stevedore>=1.20.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna<1.2.0->mlmodels==0.32.1) (1.32.0)\n",
            "Requirement already satisfied: cmd2!=0.8.3,<0.9.0,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna<1.2.0->mlmodels==0.32.1) (0.8.9)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna<1.2.0->mlmodels==0.32.1) (2.4.7)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna<1.2.0->mlmodels==0.32.1) (5.4.5)\n",
            "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna<1.2.0->mlmodels==0.32.1) (0.7.2)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.187->boto3==1.9.187->mlmodels==0.32.1) (0.15.2)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.187->boto3==1.9.187->mlmodels==0.32.1) (1.24.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna<1.2.0->mlmodels==0.32.1) (1.1.1)\n",
            "Requirement already satisfied: pyperclip in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,<0.9.0,>=0.8.0->cliff->optuna<1.2.0->mlmodels==0.32.1) (1.8.0)\n",
            "Requirement already satisfied: wcwidth; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,<0.9.0,>=0.8.0->cliff->optuna<1.2.0->mlmodels==0.32.1) (0.1.9)\n",
            "Building wheels for collected packages: mlmodels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s3V0oo8QvAwZ",
        "outputId": "eadad0b5-f04a-420b-c7bc-1e68ab941c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/arita37/mlmodels/dev/requirements_fake.txt\n",
        "!pip install -r requirements_fake.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-16 20:48:07--  https://raw.githubusercontent.com/arita37/mlmodels/dev/requirements_fake.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1154 (1.1K) [text/plain]\n",
            "Saving to: ‘requirements_fake.txt.1’\n",
            "\n",
            "\rrequirements_fake.t   0%[                    ]       0  --.-KB/s               \rrequirements_fake.t 100%[===================>]   1.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-16 20:48:07 (216 MB/s) - ‘requirements_fake.txt.1’ saved [1154/1154]\n",
            "\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git (from -r requirements_fake.txt (line 2))\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-eb92jl_k\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-eb92jl_k\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 2))\n",
            "Requirement already satisfied: mlflow==1.7.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 3)) (1.7.1)\n",
            "Requirement already satisfied: pytorch-lightning==0.7.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 8)) (0.7.3)\n",
            "Requirement already satisfied: fbprophet==0.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 11)) (0.6)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 12)) (2.2.0)\n",
            "Requirement already satisfied: torchvision==0.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 16)) (0.4.0)\n",
            "Requirement already satisfied: Pillow<7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 17)) (6.2.2)\n",
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 22)) (1.2.0)\n",
            "Requirement already satisfied: transformers==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 24)) (2.3.0)\n",
            "Requirement already satisfied: sentence-transformers==0.2.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 25)) (0.2.4)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 26)) (2.0)\n",
            "Requirement already satisfied: mxnet==1.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 36)) (1.6.0)\n",
            "Requirement already satisfied: gluonts==0.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 37)) (0.4.2)\n",
            "Requirement already satisfied: autogluon==0.0.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 38)) (0.0.5)\n",
            "Requirement already satisfied: lightgbm==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 39)) (2.3.0)\n",
            "Requirement already satisfied: deepctr in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 43)) (0.7.4)\n",
            "Requirement already satisfied: pandas<1.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 47)) (0.25.3)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 48)) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn==0.21.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 49)) (0.21.2)\n",
            "Requirement already satisfied: numexpr>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 50)) (2.7.1)\n",
            "Requirement already satisfied: sqlalchemy<=1.3.13 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 52)) (1.3.13)\n",
            "Requirement already satisfied: boto3==1.9.187 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 53)) (1.9.187)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 54)) (0.10.0)\n",
            "Requirement already satisfied: setuptools==45.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 55)) (45.2.0)\n",
            "Requirement already satisfied: python-dateutil==2.8.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 56)) (2.8.0)\n",
            "Requirement already satisfied: cli_code in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 60)) (28.1.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 64)) (0.3.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 65)) (3.2.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 66)) (2.2.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 67)) (3.6.0)\n",
            "Requirement already satisfied: matchzoo-py==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 68)) (1.1.1)\n",
            "Requirement already satisfied: tensorflow_probability<=0.7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 76)) (0.7.0)\n",
            "Requirement already satisfied: keras-mdn-layer<=0.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements_fake.txt (line 77)) (0.2.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8->-r requirements_fake.txt (line 2)) (2.3.1)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (4.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: gorilla in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.18.2)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (0.3.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (7.1.1)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (20.0.4)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (0.13.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.12.0)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.2.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (0.3)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.1.2)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.3->-r requirements_fake.txt (line 8)) (0.18.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.3->-r requirements_fake.txt (line 8)) (4.45.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.3->-r requirements_fake.txt (line 8)) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.3->-r requirements_fake.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.6/dist-packages (from fbprophet==0.6->-r requirements_fake.txt (line 11)) (0.29.16)\n",
            "Requirement already satisfied: cmdstanpy==0.4 in /usr/local/lib/python3.6/dist-packages (from fbprophet==0.6->-r requirements_fake.txt (line 11)) (0.4.0)\n",
            "Requirement already satisfied: pystan>=2.14 in /usr/local/lib/python3.6/dist-packages (from fbprophet==0.6->-r requirements_fake.txt (line 11)) (2.19.1.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet==0.6->-r requirements_fake.txt (line 11)) (3.2.1)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.6/dist-packages (from fbprophet==0.6->-r requirements_fake.txt (line 11)) (0.0.9)\n",
            "Requirement already satisfied: holidays>=0.9.5 in /usr/local/lib/python3.6/dist-packages (from fbprophet==0.6->-r requirements_fake.txt (line 11)) (0.9.12)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.6/dist-packages (from fbprophet==0.6->-r requirements_fake.txt (line 11)) (1.2)\n",
            "Requirement already satisfied: pytz<2020,>=2014.10 in /usr/local/lib/python3.6/dist-packages (from convertdate>=2.1.2->-r requirements_fake.txt (line 12)) (2018.9)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.6 in /usr/local/lib/python3.6/dist-packages (from convertdate>=2.1.2->-r requirements_fake.txt (line 12)) (0.3.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements_fake.txt (line 22)) (0.1.85)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements_fake.txt (line 22)) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers->-r requirements_fake.txt (line 22)) (0.0.41)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet==1.6.0->-r requirements_fake.txt (line 36)) (0.8.4)\n",
            "Requirement already satisfied: ujson~=1.35 in /usr/local/lib/python3.6/dist-packages (from gluonts==0.4.2->-r requirements_fake.txt (line 37)) (1.35)\n",
            "Requirement already satisfied: pydantic~=1.1 in /usr/local/lib/python3.6/dist-packages (from gluonts==0.4.2->-r requirements_fake.txt (line 37)) (1.4)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (0.22)\n",
            "Requirement already satisfied: ConfigSpace<=0.4.10 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (0.4.10)\n",
            "Requirement already satisfied: cryptography>=2.8 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (2.9)\n",
            "Requirement already satisfied: gluoncv>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (0.6.0)\n",
            "Requirement already satisfied: dask==2.6.0 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (2.6.0)\n",
            "Requirement already satisfied: paramiko>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (2.7.1)\n",
            "Requirement already satisfied: gluonnlp==0.8.1 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (0.8.1)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (6.0.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (5.4.8)\n",
            "Requirement already satisfied: distributed==2.6.0 in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (2.6.0)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.6/dist-packages (from autogluon==0.0.5->-r requirements_fake.txt (line 38)) (0.7.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from deepctr->-r requirements_fake.txt (line 43)) (2.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->-r requirements_fake.txt (line 49)) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.187 in /usr/local/lib/python3.6/dist-packages (from boto3==1.9.187->-r requirements_fake.txt (line 53)) (1.12.253)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3==1.9.187->-r requirements_fake.txt (line 53)) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3==1.9.187->-r requirements_fake.txt (line 53)) (0.2.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements_fake.txt (line 66)) (0.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements_fake.txt (line 67)) (1.11.1)\n",
            "Requirement already satisfied: dill>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from matchzoo-py==1.1.1->-r requirements_fake.txt (line 68)) (0.3.1.1)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from matchzoo-py==1.1.1->-r requirements_fake.txt (line 68)) (2.4)\n",
            "Requirement already satisfied: hyperopt==0.1.2 in /usr/local/lib/python3.6/dist-packages (from matchzoo-py==1.1.1->-r requirements_fake.txt (line 68)) (0.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow_probability<=0.7.0->-r requirements_fake.txt (line 76)) (4.4.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8->-r requirements_fake.txt (line 2)) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8->-r requirements_fake.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker>=4.0.0->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (0.57.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.1.2)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython>=2.1.0->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (4.0.4)\n",
            "Requirement already satisfied: configparser>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (5.0.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (0.8.7)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (0.7.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (2.11.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.3->-r requirements_fake.txt (line 8)) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.3->-r requirements_fake.txt (line 8)) (1.28.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.3->-r requirements_fake.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.3->-r requirements_fake.txt (line 8)) (0.9.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet==0.6->-r requirements_fake.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet==0.6->-r requirements_fake.txt (line 11)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet==0.6->-r requirements_fake.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.6/dist-packages (from LunarCalendar>=0.0.9->fbprophet==0.6->-r requirements_fake.txt (line 11)) (3.7.7.1)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic~=1.1->gluonts==0.4.2->-r requirements_fake.txt (line 37)) (0.7)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (4.4.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<=0.4.10->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (3.6.6)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (1.14.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from gluoncv>=0.5.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (1.7.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.5.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (3.1.7)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from paramiko>=2.5.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (1.3.0)\n",
            "Requirement already satisfied: toolz>=0.7.4 in /usr/local/lib/python3.6/dist-packages (from distributed==2.6.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (0.10.0)\n",
            "Requirement already satisfied: tblib in /usr/local/lib/python3.6/dist-packages (from distributed==2.6.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (1.6.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from distributed==2.6.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (2.0.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from distributed==2.6.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (1.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/dist-packages (from distributed==2.6.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (2.1.0)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (20.4.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.187->boto3==1.9.187->-r requirements_fake.txt (line 53)) (0.15.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->-r requirements_fake.txt (line 66)) (1.6.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->-r requirements_fake.txt (line 67)) (2.49.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt==0.1.2->matchzoo-py==1.1.1->-r requirements_fake.txt (line 68)) (3.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (1.1.1)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow==1.7.1->-r requirements_fake.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (1.3.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (2.20)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.6/dist-packages (from zict>=0.1.3->distributed==2.6.0->autogluon==0.0.5->-r requirements_fake.txt (line 38)) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r requirements_fake.txt (line 66)) (3.1.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=bb8ed57f078c728a0aef6d0d8600ce24ac840b9f095d85910e5b9af9e1d1c1b6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7vas5hck/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWkFI6056SgJ",
        "colab_type": "code",
        "outputId": "b2b3948f-98e6-45d9-ae4c-b0a5bf0d3e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "docs\t\t      README_model_list.md     run_gitpod.md\n",
            "LICENSE\t\t      README_papers.md\t       run_git_precommit.bat\n",
            "MANIFEST.in\t      README_usage_CLI.md      run_jupyter.sh\n",
            "mlmodels\t      README_usage.md\t       run_pycharm.bat\n",
            "pullrequest\t      README_usage_USECASE.md  run_pypi.py\n",
            "pullrequest.json      requirements_base.txt    runs.sh\n",
            "pylintrc\t      requirements_fake.txt    setup.cfg\n",
            "README_addmodel.md    requirements_fake.txt.1  setup.py\n",
            "README_index_doc.md   requirements.txt\t       Test.txt\n",
            "README_index_doc.py   run_basic_check.py       zconda\n",
            "README_index_doc.txt  run_doc.bat\t       ztest\n",
            "README.md\t      run_doc.py\t       zwork\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5OOlPk47WAx",
        "colab_type": "code",
        "outputId": "8057a643-a89f-4e7e-921a-4f5d6180c5ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir zwork && cd zwork"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘zwork’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdmgilrU7Wf1",
        "colab_type": "code",
        "outputId": "6de4d749-36e7-44a1-c4e2-d046be9ba32d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!ml_optim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deprecaton set to False\n",
            "\n",
            "  ('path_save', '/content/mlmodels/ztest/optuna_1lstm/', '/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv') \n",
            "\n",
            "  ('model details', 'model_tf.1_lstm', {'engine_pars': {'engine': 'optuna', 'method': 'normal', 'ntrials': 2, 'metric_target': 'loss'}, 'learning_rate': {'type': 'log_uniform', 'init': 0.01, 'range': [0.001, 0.1]}, 'num_layers': {'type': 'int', 'init': 2, 'range': [2, 4]}, 'size': {'type': 'int', 'init': 6, 'range': [6, 6]}, 'output_size': {'type': 'int', 'init': 6, 'range': [6, 6]}, 'size_layer': {'type': 'categorical', 'value': [128, 256]}, 'timestep': {'type': 'categorical', 'value': [5]}, 'epoch': {'type': 'categorical', 'value': [2]}}) \n",
            "\n",
            "  ({'model_uri': 'model_tf.1_lstm', 'learning_rate': 0.001, 'num_layers': 1, 'size': None, 'size_layer': 128, 'output_size': None, 'timestep': 4, 'epoch': 2}, {'data_path': '/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas'}, {}, {'engine_pars': {'engine': 'optuna', 'method': 'normal', 'ntrials': 2, 'metric_target': 'loss'}, 'learning_rate': {'type': 'log_uniform', 'init': 0.01, 'range': [0.001, 0.1]}, 'num_layers': {'type': 'int', 'init': 2, 'range': [2, 4]}, 'size': {'type': 'int', 'init': 6, 'range': [6, 6]}, 'output_size': {'type': 'int', 'init': 6, 'range': [6, 6]}, 'size_layer': {'type': 'categorical', 'value': [128, 256]}, 'timestep': {'type': 'categorical', 'value': [5]}, 'epoch': {'type': 'categorical', 'value': [2]}}) \n",
            "\n",
            "  (<module 'mlmodels.model_tf.1_lstm' from '/usr/local/lib/python3.6/dist-packages/mlmodels/model_tf/1_lstm.py'>,) \n",
            "\n",
            "  ('###### Hyper-optimization through study   ##################################',) \n",
            "\n",
            "  ('check', <module 'mlmodels.model_tf.1_lstm' from '/usr/local/lib/python3.6/dist-packages/mlmodels/model_tf/1_lstm.py'>, {'data_path': '/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas'}) \n",
            "{'data_path': '/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas'}\n",
            "/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv\n",
            "         Date  ...   Volume\n",
            "0  2016-11-02  ...  1872400\n",
            "1  2016-11-03  ...  1943200\n",
            "2  2016-11-04  ...  2134800\n",
            "3  2016-11-07  ...  1585100\n",
            "4  2016-11-08  ...  1350800\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "          0  ...         5\n",
            "0  0.706562  ...  0.153665\n",
            "1  0.458824  ...  0.174523\n",
            "2  0.083484  ...  0.230969\n",
            "3  0.622851  ...  0.069025\n",
            "4  0.824209  ...  0.000000\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "\u001b[32m[I 2020-04-16 21:05:23,839]\u001b[0m Finished trial#0 resulted in value: 6.620846331119537. Current best value is 6.620846331119537 with parameters: {'learning_rate': 0.05460385722588979, 'num_layers': 2, 'size': 6, 'output_size': 6, 'size_layer': 256, 'timestep': 5, 'epoch': 2}.\u001b[0m\n",
            "\n",
            "  ('check', <module 'mlmodels.model_tf.1_lstm' from '/usr/local/lib/python3.6/dist-packages/mlmodels/model_tf/1_lstm.py'>, {'data_path': '/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas'}) \n",
            "{'data_path': '/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas'}\n",
            "/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv\n",
            "         Date  ...   Volume\n",
            "0  2016-11-02  ...  1872400\n",
            "1  2016-11-03  ...  1943200\n",
            "2  2016-11-04  ...  2134800\n",
            "3  2016-11-07  ...  1585100\n",
            "4  2016-11-08  ...  1350800\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "          0  ...         5\n",
            "0  0.706562  ...  0.153665\n",
            "1  0.458824  ...  0.174523\n",
            "2  0.083484  ...  0.230969\n",
            "3  0.622851  ...  0.069025\n",
            "4  0.824209  ...  0.000000\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "\u001b[32m[I 2020-04-16 21:05:25,248]\u001b[0m Finished trial#1 resulted in value: 0.4267284870147705. Current best value is 0.4267284870147705 with parameters: {'learning_rate': 0.01093035113507769, 'num_layers': 2, 'size': 6, 'output_size': 6, 'size_layer': 256, 'timestep': 5, 'epoch': 2}.\u001b[0m\n",
            "\n",
            " ################################### ('Optim, finished',) ###################################\n",
            "\n",
            "  ('### Save Stats   ##########################################################',) \n",
            "\n",
            "  ('### Run Model with best   #################################################',) \n",
            "{'data_path': '/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv', 'data_type': 'pandas'}\n",
            "/usr/local/lib/python3.6/dist-packages/mlmodels/dataset/timeseries/GOOG-year_small.csv\n",
            "         Date  ...   Volume\n",
            "0  2016-11-02  ...  1872400\n",
            "1  2016-11-03  ...  1943200\n",
            "2  2016-11-04  ...  2134800\n",
            "3  2016-11-07  ...  1585100\n",
            "4  2016-11-08  ...  1350800\n",
            "\n",
            "[5 rows x 7 columns]\n",
            "          0  ...         5\n",
            "0  0.706562  ...  0.153665\n",
            "1  0.458824  ...  0.174523\n",
            "2  0.083484  ...  0.230969\n",
            "3  0.622851  ...  0.069025\n",
            "4  0.824209  ...  0.000000\n",
            "\n",
            "[5 rows x 6 columns]\n",
            "\n",
            "  ('#### Saving     ###########################################################',) \n",
            "{'path': 'ztest/optuna_1lstm/', 'model_type': 'model_tf', 'model_uri': 'model_tf-1_lstm'}\n",
            "\n",
            " ############################## ('Finished OPTIMIZATION',) ##############################\n",
            "{'model_uri': 'model_tf.1_lstm', 'learning_rate': 0.01093035113507769, 'num_layers': 2, 'size': 6, 'size_layer': 256, 'output_size': 6, 'timestep': 5, 'epoch': 2, 'best_value': 0.4267284870147705, 'model_name': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTV86eiqtgUr",
        "colab_type": "text"
      },
      "source": [
        "# pretrained resnet18 on MNIST (torch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTf9qA5k4Q_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import library\n",
        "import mlmodels\n",
        "from mlmodels.models import module_load\n",
        "from mlmodels.util import path_norm_dict, path_norm, params_json_load\n",
        "from mlmodels.metrics import metrics_eval\n",
        "import json\n",
        "\n",
        "\n",
        "#### Model URI and Config JSON\n",
        "model_uri   = \"model_tch.torchhub.py\"\n",
        "config_path = path_norm( 'dataset/json/benchmark_cnn/resnet18_benchmark_mnist.json'  )\n",
        "config_mode = \"test\"  ### test/prod\n",
        "\n",
        "\n",
        "\n",
        "#### Model Parameters\n",
        "model_pars, data_pars, compute_pars, out_pars = params_json_load(config_path, config_mode= config_mode)\n",
        "print( model_pars, data_pars, compute_pars, out_pars)\n",
        "\n",
        "print('[INFO] model '+  model_pars['model']  + ' is training')\n",
        "\n",
        "#### Setup Model \n",
        "module         = module_load( model_uri)\n",
        "model          = module.Model(model_pars, data_pars, compute_pars) \n",
        "\n",
        "#### Fit\n",
        "model, session = module.fit(model, data_pars, compute_pars, out_pars)           #### fit model\n",
        "metrics_val    = module.fit_metrics(model, data_pars, compute_pars, out_pars)   #### Check fit metrics\n",
        "print(metrics_val)\n",
        "\n",
        "\n",
        "#### Inference\n",
        "ypred          = module.predict(model, session, data_pars, compute_pars, out_pars)   \n",
        "print(ypred)\n",
        "\n",
        "\n",
        "\n",
        "#### Save/Load\n",
        "module.save(model, save_pars ={ 'path': out_pars['path'] +\"/model/\"})\n",
        "\n",
        "model2 = module.load(load_pars ={ 'path': out_pars['path'] +\"/model/\"})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoU7BLfdNga4",
        "colab_type": "text"
      },
      "source": [
        "# pretrained resnet34 on MNIST (torch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUS6uPatNxZf",
        "colab_type": "code",
        "outputId": "3210d1b3-c632-4b5f-83b3-d7e9c4e0ebfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import library\n",
        "import mlmodels\n",
        "from mlmodels.models import module_load\n",
        "from mlmodels.util import path_norm_dict, path_norm, params_json_load\n",
        "import json\n",
        "\n",
        "\n",
        "#### Model URI and Config JSON\n",
        "model_uri   = \"model_tch.torchhub.py\"\n",
        "config_path = path_norm( 'dataset/json/benchmark_cnn/resnet34_benchmark_mnist.json'  )\n",
        "config_mode = \"test\"  ### test/prod\n",
        "\n",
        "\n",
        "\n",
        "#### Model Parameters\n",
        "model_pars, data_pars, compute_pars, out_pars = params_json_load(config_path, config_mode= config_mode)\n",
        "print( model_pars, data_pars, compute_pars, out_pars)\n",
        "\n",
        "#### Setup Model \n",
        "module         = module_load( model_uri)\n",
        "model          = module.Model(model_pars, data_pars, compute_pars) \n",
        "\n",
        "#### Fit\n",
        "model, session = module.fit(model, data_pars, compute_pars, out_pars)           #### fit model\n",
        "metrics_val    = module.fit_metrics(model, data_pars, compute_pars, out_pars)   #### Check fit metrics\n",
        "print(metrics_val)\n",
        "\n",
        "\n",
        "#### Inference\n",
        "ypred          = module.predict(model, session, data_pars, compute_pars, out_pars)   \n",
        "print(ypred)\n",
        "\n",
        "\n",
        "\n",
        "#### Save/Load\n",
        "module.save(model, save_pars ={ 'path': out_pars['path'] +\"/model/\"})\n",
        "\n",
        "model2 = module.load(load_pars ={ 'path': out_pars['path'] +\"/model/\"})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'model_uri': 'model_tch.torchhub.py', 'repo_uri': 'pytorch/vision', 'model': 'resnet34', 'num_classes': 10, 'pretrained': 0, '_comment': '0: False, 1: True', 'num_layers': 1, 'size': 6, 'size_layer': 128, 'output_size': 6, 'timestep': 4, 'epoch': 2} {'dataset': 'MNIST', 'data_path': 'dataset/vision/', 'train_batch_size': 4, 'test_batch_size': 4} {'distributed': 'mpi', 'max_batch_sample': 5, 'epochs': 2, 'learning_rate': 0.001} {'checkpointdir': 'ztest/model_tch/torchhub/restnet34/checkpoints/', 'path': 'ztest/model_tch/torchhub/restnet34/'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.0008923704942067465 \t Accuracy: 0.013333333656191826\n",
            "Train Epoch: 1 \t Loss: 0.008371993255615235 \t Accuracy: 0.0\n",
            "model saves at 0.0 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.001047427805264791 \t Accuracy: 0.013333333656191826\n",
            "Train Epoch: 2 \t Loss: 0.013246942520141601 \t Accuracy: 0.0\n",
            "None\n",
            "(array([9, 9, 9, 9]), array([0, 1, 6, 5]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQRwYbYiNtDe",
        "colab_type": "text"
      },
      "source": [
        "# pretrained resnet50 on MNIST (torch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1XTQlewOHkg",
        "colab_type": "code",
        "outputId": "fb33e7be-d7b1-4788-e614-2ecfc7f2fe08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import library\n",
        "import mlmodels\n",
        "from mlmodels.models import module_load\n",
        "from mlmodels.util import path_norm_dict, path_norm, params_json_load\n",
        "import json\n",
        "\n",
        "\n",
        "#### Model URI and Config JSON\n",
        "model_uri   = \"model_tch.torchhub.py\"\n",
        "config_path = path_norm( 'dataset/json/benchmark_cnn/resnet50_benchmark_mnist.json'  )\n",
        "config_mode = \"test\"  ### test/prod\n",
        "\n",
        "\n",
        "\n",
        "#### Model Parameters\n",
        "model_pars, data_pars, compute_pars, out_pars = params_json_load(config_path, config_mode= config_mode)\n",
        "print( model_pars, data_pars, compute_pars, out_pars)\n",
        "\n",
        "#### Setup Model \n",
        "module         = module_load( model_uri)\n",
        "model          = module.Model(model_pars, data_pars, compute_pars) \n",
        "\n",
        "#### Fit\n",
        "model, session = module.fit(model, data_pars, compute_pars, out_pars)           #### fit model\n",
        "metrics_val    = module.fit_metrics(model, data_pars, compute_pars, out_pars)   #### Check fit metrics\n",
        "print(metrics_val)\n",
        "\n",
        "\n",
        "#### Inference\n",
        "ypred          = module.predict(model, session, data_pars, compute_pars, out_pars)   \n",
        "print(ypred)\n",
        "\n",
        "\n",
        "\n",
        "#### Save/Load\n",
        "module.save(model, save_pars ={ 'path': out_pars['path'] +\"/model/\"})\n",
        "\n",
        "model2 = module.load(load_pars ={ 'path': out_pars['path'] +\"/model/\"})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'model_uri': 'model_tch.torchhub.py', 'repo_uri': 'pytorch/vision', 'model': 'resnet50', 'num_classes': 10, 'pretrained': 0, '_comment': '0: False, 1: True', 'num_layers': 1, 'size': 6, 'size_layer': 128, 'output_size': 6, 'timestep': 4, 'epoch': 2} {'dataset': 'MNIST', 'data_path': 'dataset/vision/', 'train_batch_size': 4, 'test_batch_size': 4} {'distributed': 'mpi', 'max_batch_sample': 5, 'epochs': 2, 'learning_rate': 0.001} {'checkpointdir': 'ztest/model_tch/torchhub/restnet18/checkpoints/', 'path': 'ztest/model_tch/torchhub/restnet18/'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.0014383286635080974 \t Accuracy: 0.006666666828095913\n",
            "Train Epoch: 1 \t Loss: 0.0046876011848449705 \t Accuracy: 0.03999999910593033\n",
            "model saves at 0.03999999910593033 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.0010994330167770387 \t Accuracy: 0.02666666731238365\n",
            "Train Epoch: 2 \t Loss: 0.00481456937789917 \t Accuracy: 0.07999999821186066\n",
            "model saves at 0.07999999821186066 accuracy\n",
            "None\n",
            "(array([9, 9, 9, 9]), array([8, 1, 6, 0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6MQyDcvzwt7",
        "colab_type": "text"
      },
      "source": [
        "# pretrined models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvaiDFJl7zDL",
        "colab_type": "code",
        "outputId": "ea922e5c-4377-4ca6-d0e8-5de8715670ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# import library\n",
        "import mlmodels\n",
        "from mlmodels.models import module_load\n",
        "from mlmodels.util import path_norm_dict, path_norm, params_json_load\n",
        "from mlmodels.metrics import metrics_eval\n",
        "import json\n",
        "\n",
        "\n",
        "#### Model URI and Config JSON\n",
        "model_uri   = \"model_tch.torchhub.py\"\n",
        "config_path = path_norm( 'dataset/json/benchmark_cnn/resnet18_benchmark_mnist.json'  )\n",
        "config_mode = \"test\"  ### test/prod\n",
        "\n",
        "\n",
        "\n",
        "#### Model Parameters\n",
        "model_pars, data_pars, compute_pars, out_pars = params_json_load(config_path, config_mode= config_mode)\n",
        "print( model_pars, data_pars, compute_pars, out_pars)\n",
        "model_pars =   {\n",
        "                \"model_uri\": \"model_tch.torchhub.py\",\n",
        "                \"repo_uri\": \"pytorch/vision\",\n",
        "                \"model\": \"resnet18\",\n",
        "                \"num_classes\": 10,\n",
        "                \"pretrained\": 0,  \"_comment\": \"0: False, 1: True\",\n",
        "                \"num_layers\": 5,\n",
        "                \"size\": 6,\n",
        "                \"size_layer\": 128,\n",
        "                \"output_size\": 6,\n",
        "                \"timestep\": 4,\n",
        "                \"epoch\": 2\n",
        "            }\n",
        "models = ['alexnet', 'densenet121', 'densenet169', 'densenet201',\n",
        "'densenet161', 'inception_v3', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet50_2', 'wide_resnet101_2', 'squeezenet1_0',\n",
        "'squeezenet1_1', 'vgg11', 'vgg13', 'vgg16', 'vgg19', 'vgg11_bn', 'vgg13_bn', 'vgg16_bn', 'vgg19_bn',\n",
        "'googlenet', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'mobilenet_v2']\n",
        "\n",
        "valid_models =  ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet50_2', 'wide_resnet101_2', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0']\n",
        "#yes\n",
        "#'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0','wide_resnet101_2'\n",
        "#no\n",
        "#'mobilenet_v2','googlenet','vgg*','squeezenet1_1','alexnet','densenet','inception_v3'\n",
        "\n",
        "#errors \n",
        "#'GoogLeNetOutputs' object has no attribute 'log_softmax'\n",
        "#'VGG' object has no attribute 'fc'\n",
        "#'SqueezeNet' object has no attribute 'fc'\n",
        "#'AlexNet' object has no attribute 'fc'\n",
        "#'DenseNet' object has no attribute 'fc'\n",
        "# Calculated padded input size per channel: (1 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size\n",
        "\n",
        "for model_name in valid_models:\n",
        "    print('[INFO] model '+  model_name + ' is training')\n",
        "    \n",
        "    model_pars['model'] = model_name\n",
        "    out_pars = {\n",
        "                    \"checkpointdir\": \"ztest/model_tch/torchhub/\"+ model_pars['model'] +\"/checkpoints/\",\n",
        "                    \"path\": \"ztest/model_tch/torchhub/\"+ model_pars['model'] +\"/\"\n",
        "                }\n",
        "\n",
        "    #### Setup Model \n",
        "    module         = module_load( model_uri)\n",
        "    model          = module.Model(model_pars, data_pars, compute_pars) \n",
        "\n",
        "    #### Fit\n",
        "    model, session = module.fit(model, data_pars, compute_pars, out_pars)           #### fit model\n",
        "    metrics_val    = module.fit_metrics(model, data_pars, compute_pars, out_pars)   #### Check fit metrics\n",
        "    print(metrics_val)\n",
        "\n",
        "\n",
        "    #### Inference\n",
        "    ypred          = module.predict(model, session, data_pars, compute_pars, out_pars)   \n",
        "    print(ypred)\n",
        "\n",
        "\n",
        "\n",
        "    #### Save/Load\n",
        "    module.save(model, save_pars ={ 'path': out_pars['path'] +\"/model/\"})\n",
        "\n",
        "    model2 = module.load(load_pars ={ 'path': out_pars['path'] +\"/model/\"})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'model_uri': 'model_tch.torchhub.py', 'repo_uri': 'pytorch/vision', 'model': 'resnet18', 'num_classes': 10, 'pretrained': 0, '_comment': '0: False, 1: True', 'num_layers': 5, 'size': 6, 'size_layer': 128, 'output_size': 6, 'timestep': 4, 'epoch': 2} {'dataset': 'MNIST', 'data_path': 'dataset/vision/', 'train_batch_size': 100, 'test_batch_size': 10} {'distributed': 'mpi', 'max_batch_sample': 100, 'epochs': 10, 'learning_rate': 0.001} {'checkpointdir': 'ztest/model_tch/torchhub/restnet18/checkpoints/', 'path': 'ztest/model_tch/torchhub/restnet18/'}\n",
            "[INFO] model resnet18 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.04626604656378428 \t Accuracy: 1520.3333740234375\n",
            "Train Epoch: 1 \t Loss: 0.012397324007120914 \t Accuracy: 96.10000610351562\n",
            "model saves at 96.10000610351562 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.020792350123325982 \t Accuracy: 1601.8333740234375\n",
            "Train Epoch: 2 \t Loss: 0.008750397906987928 \t Accuracy: 97.50000762939453\n",
            "model saves at 97.50000762939453 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.01578744935647895 \t Accuracy: 1619.5\n",
            "Train Epoch: 3 \t Loss: 0.00787820408155676 \t Accuracy: 97.50000762939453\n",
            "Train Epoch: 4 \t Loss: 0.013674456618415813 \t Accuracy: 1625.3333740234375\n",
            "Train Epoch: 4 \t Loss: 0.015982719413470476 \t Accuracy: 94.80000305175781\n",
            "Train Epoch: 5 \t Loss: 0.010490685791398087 \t Accuracy: 1635.3333740234375\n",
            "Train Epoch: 5 \t Loss: 0.00998592904729594 \t Accuracy: 96.70000457763672\n",
            "Train Epoch: 6 \t Loss: 0.010418962844802688 \t Accuracy: 1633.3333740234375\n",
            "Train Epoch: 6 \t Loss: 0.00867193297738413 \t Accuracy: 97.30000305175781\n",
            "Train Epoch: 7 \t Loss: 0.01210686774769177 \t Accuracy: 1632.8333740234375\n",
            "Train Epoch: 7 \t Loss: 0.0053950595250789775 \t Accuracy: 98.30000305175781\n",
            "model saves at 98.30000305175781 accuracy\n",
            "Train Epoch: 8 \t Loss: 0.009931503937890133 \t Accuracy: 1638.5\n",
            "Train Epoch: 8 \t Loss: 0.005252781924158626 \t Accuracy: 98.30000305175781\n",
            "Train Epoch: 9 \t Loss: 0.00848170647281222 \t Accuracy: 1641.8333740234375\n",
            "Train Epoch: 9 \t Loss: 0.005019584214089263 \t Accuracy: 98.4000015258789\n",
            "model saves at 98.4000015258789 accuracy\n",
            "Train Epoch: 10 \t Loss: 0.008183305210938368 \t Accuracy: 1642.666748046875\n",
            "Train Epoch: 10 \t Loss: 0.0036569741511775647 \t Accuracy: 99.00000762939453\n",
            "model saves at 99.00000762939453 accuracy\n",
            "None\n",
            "(array([0, 3, 3, 9, 4, 9, 4, 3, 6, 9]), array([0, 3, 3, 9, 4, 9, 4, 3, 6, 9]))\n",
            "[INFO] model resnet34 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.05809623325864474 \t Accuracy: 1483.8333740234375\n",
            "Train Epoch: 1 \t Loss: 0.026028927834006028 \t Accuracy: 92.80000305175781\n",
            "model saves at 92.80000305175781 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.02204672328506907 \t Accuracy: 1602.666748046875\n",
            "Train Epoch: 2 \t Loss: 0.01394102504942566 \t Accuracy: 95.20000457763672\n",
            "model saves at 95.20000457763672 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.01837865364116927 \t Accuracy: 1611.0\n",
            "Train Epoch: 3 \t Loss: 0.010718085373475333 \t Accuracy: 96.60000610351562\n",
            "model saves at 96.60000610351562 accuracy\n",
            "Train Epoch: 4 \t Loss: 0.015048035966077199 \t Accuracy: 1621.8333740234375\n",
            "Train Epoch: 4 \t Loss: 0.008074402509024367 \t Accuracy: 97.70000457763672\n",
            "model saves at 97.70000457763672 accuracy\n",
            "Train Epoch: 5 \t Loss: 0.013105833133837829 \t Accuracy: 1630.166748046875\n",
            "Train Epoch: 5 \t Loss: 0.007120062192028854 \t Accuracy: 97.9000015258789\n",
            "model saves at 97.9000015258789 accuracy\n",
            "Train Epoch: 6 \t Loss: 0.013575476173621913 \t Accuracy: 1622.666748046875\n",
            "Train Epoch: 6 \t Loss: 0.011540834291547071 \t Accuracy: 97.30000305175781\n",
            "Train Epoch: 7 \t Loss: 0.010146938012136767 \t Accuracy: 1636.3333740234375\n",
            "Train Epoch: 7 \t Loss: 0.003981099286902463 \t Accuracy: 98.70000457763672\n",
            "model saves at 98.70000457763672 accuracy\n",
            "Train Epoch: 8 \t Loss: 0.010952701459173113 \t Accuracy: 1635.166748046875\n",
            "Train Epoch: 8 \t Loss: 0.008542893849546089 \t Accuracy: 97.20000457763672\n",
            "Train Epoch: 9 \t Loss: 0.008981621815667798 \t Accuracy: 1640.5\n",
            "Train Epoch: 9 \t Loss: 0.005910662608999701 \t Accuracy: 98.10000610351562\n",
            "Train Epoch: 10 \t Loss: 0.00983415116633599 \t Accuracy: 1638.3333740234375\n",
            "Train Epoch: 10 \t Loss: 0.012081351142493077 \t Accuracy: 96.4000015258789\n",
            "None\n",
            "(array([5, 1, 7, 9, 9, 8, 0, 1, 6, 4]), array([5, 1, 7, 9, 9, 8, 0, 1, 6, 4]))\n",
            "[INFO] model resnet50 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.12403995762268702 \t Accuracy: 1286.5\n",
            "Train Epoch: 1 \t Loss: 0.02333721194823738 \t Accuracy: 92.70000457763672\n",
            "model saves at 92.70000457763672 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.03430478896324833 \t Accuracy: 1561.3333740234375\n",
            "Train Epoch: 2 \t Loss: 0.012350371230160818 \t Accuracy: 95.80000305175781\n",
            "model saves at 95.80000305175781 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.022347894214714566 \t Accuracy: 1598.0\n",
            "Train Epoch: 3 \t Loss: 0.01296252601960441 \t Accuracy: 95.9000015258789\n",
            "model saves at 95.9000015258789 accuracy\n",
            "Train Epoch: 4 \t Loss: 0.019448546785861255 \t Accuracy: 1605.0\n",
            "Train Epoch: 4 \t Loss: 0.013925839315867052 \t Accuracy: 95.80000305175781\n",
            "Train Epoch: 5 \t Loss: 0.01762229194243749 \t Accuracy: 1613.5\n",
            "Train Epoch: 5 \t Loss: 0.004873002771801111 \t Accuracy: 98.50000762939453\n",
            "model saves at 98.50000762939453 accuracy\n",
            "Train Epoch: 6 \t Loss: 0.012535808928854142 \t Accuracy: 1630.3333740234375\n",
            "Train Epoch: 6 \t Loss: 0.007229986834485317 \t Accuracy: 97.80000305175781\n",
            "Train Epoch: 7 \t Loss: 0.012297226409427821 \t Accuracy: 1628.0\n",
            "Train Epoch: 7 \t Loss: 0.010113026622993857 \t Accuracy: 97.00000762939453\n",
            "Train Epoch: 8 \t Loss: 0.012189136940675476 \t Accuracy: 1629.5\n",
            "Train Epoch: 8 \t Loss: 0.006684875456092414 \t Accuracy: 98.20000457763672\n",
            "Train Epoch: 9 \t Loss: 0.01120764627897491 \t Accuracy: 1633.8333740234375\n",
            "Train Epoch: 9 \t Loss: 0.00606862994754556 \t Accuracy: 98.30000305175781\n",
            "Train Epoch: 10 \t Loss: 0.009613608108678211 \t Accuracy: 1638.166748046875\n",
            "Train Epoch: 10 \t Loss: 0.005097380667211837 \t Accuracy: 98.10000610351562\n",
            "None\n",
            "(array([3, 7, 4, 6, 9, 5, 9, 8, 3, 0]), array([3, 3, 4, 6, 9, 5, 9, 8, 3, 0]))\n",
            "[INFO] model resnet101 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.1573677015552918 \t Accuracy: 1177.666748046875\n",
            "Train Epoch: 1 \t Loss: 0.062245043247938156 \t Accuracy: 80.9000015258789\n",
            "model saves at 80.9000015258789 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.041863326852520304 \t Accuracy: 1537.166748046875\n",
            "Train Epoch: 2 \t Loss: 0.01866881445090985 \t Accuracy: 94.50000762939453\n",
            "model saves at 94.50000762939453 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.028610089868307112 \t Accuracy: 1580.8333740234375\n",
            "Train Epoch: 3 \t Loss: 0.02051883143334999 \t Accuracy: 93.70000457763672\n",
            "Train Epoch: 4 \t Loss: 0.022897449806332588 \t Accuracy: 1598.8333740234375\n",
            "Train Epoch: 4 \t Loss: 0.013533921823836862 \t Accuracy: 96.10000610351562\n",
            "model saves at 96.10000610351562 accuracy\n",
            "Train Epoch: 5 \t Loss: 0.019942429624497892 \t Accuracy: 1605.5\n",
            "Train Epoch: 5 \t Loss: 0.008536152833752567 \t Accuracy: 97.30000305175781\n",
            "model saves at 97.30000305175781 accuracy\n",
            "Train Epoch: 6 \t Loss: 0.01708400659263134 \t Accuracy: 1614.166748046875\n",
            "Train Epoch: 6 \t Loss: 0.012908520835859236 \t Accuracy: 95.80000305175781\n",
            "Train Epoch: 7 \t Loss: 0.01653410202357918 \t Accuracy: 1617.5\n",
            "Train Epoch: 7 \t Loss: 0.015486667262841366 \t Accuracy: 95.50000762939453\n",
            "Train Epoch: 8 \t Loss: 0.011902450012664 \t Accuracy: 1630.666748046875\n",
            "Train Epoch: 8 \t Loss: 0.009728639756387564 \t Accuracy: 97.10000610351562\n",
            "Train Epoch: 9 \t Loss: 0.012854968551546336 \t Accuracy: 1628.5\n",
            "Train Epoch: 9 \t Loss: 0.008802103223722952 \t Accuracy: 97.60000610351562\n",
            "model saves at 97.60000610351562 accuracy\n",
            "Train Epoch: 10 \t Loss: 0.010723453767132013 \t Accuracy: 1635.0\n",
            "Train Epoch: 10 \t Loss: 0.007484279580134171 \t Accuracy: 97.20000457763672\n",
            "None\n",
            "(array([6, 1, 6, 5, 8, 2, 7, 0, 3, 8]), array([6, 1, 6, 5, 8, 2, 7, 0, 3, 7]))\n",
            "[INFO] model resnet152 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.21264601230621338 \t Accuracy: 1001.0\n",
            "Train Epoch: 1 \t Loss: 0.08910797031223774 \t Accuracy: 75.10000610351562\n",
            "model saves at 75.10000610351562 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.06639009356498718 \t Accuracy: 1457.166748046875\n",
            "Train Epoch: 2 \t Loss: 0.03055684158112854 \t Accuracy: 91.20000457763672\n",
            "model saves at 91.20000457763672 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.04043089377383391 \t Accuracy: 1543.0\n",
            "Train Epoch: 3 \t Loss: 0.02676702433498576 \t Accuracy: 90.60000610351562\n",
            "Train Epoch: 4 \t Loss: 0.03290961203475793 \t Accuracy: 1561.8333740234375\n",
            "Train Epoch: 4 \t Loss: 0.017437514327932148 \t Accuracy: 94.30000305175781\n",
            "model saves at 94.30000305175781 accuracy\n",
            "Train Epoch: 5 \t Loss: 0.02320130364969373 \t Accuracy: 1595.8333740234375\n",
            "Train Epoch: 5 \t Loss: 0.0193459502402693 \t Accuracy: 94.20000457763672\n",
            "Train Epoch: 6 \t Loss: 0.02255682791893681 \t Accuracy: 1597.666748046875\n",
            "Train Epoch: 6 \t Loss: 0.0171949596395134 \t Accuracy: 94.70000457763672\n",
            "model saves at 94.70000457763672 accuracy\n",
            "Train Epoch: 7 \t Loss: 0.01814936296703915 \t Accuracy: 1612.666748046875\n",
            "Train Epoch: 7 \t Loss: 0.017276930701336825 \t Accuracy: 94.9000015258789\n",
            "model saves at 94.9000015258789 accuracy\n",
            "Train Epoch: 8 \t Loss: 0.020464932496349016 \t Accuracy: 1607.8333740234375\n",
            "Train Epoch: 8 \t Loss: 0.01805699489242397 \t Accuracy: 95.4000015258789\n",
            "model saves at 95.4000015258789 accuracy\n",
            "Train Epoch: 9 \t Loss: 0.016341278565426668 \t Accuracy: 1616.5\n",
            "Train Epoch: 9 \t Loss: 0.013149893757596147 \t Accuracy: 96.30000305175781\n",
            "model saves at 96.30000305175781 accuracy\n",
            "Train Epoch: 10 \t Loss: 0.01359692774247378 \t Accuracy: 1625.5\n",
            "Train Epoch: 10 \t Loss: 0.01048684729240631 \t Accuracy: 97.00000762939453\n",
            "model saves at 97.00000762939453 accuracy\n",
            "None\n",
            "(array([5, 2, 9, 5, 9, 3, 0, 2, 6, 4]), array([5, 2, 9, 5, 9, 3, 0, 2, 6, 4]))\n",
            "[INFO] model resnext50_32x4d is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.14176210934917133 \t Accuracy: 1236.3333740234375\n",
            "Train Epoch: 1 \t Loss: 0.02271287448820658 \t Accuracy: 92.50000762939453\n",
            "model saves at 92.50000762939453 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.04108853397270044 \t Accuracy: 1542.8333740234375\n",
            "Train Epoch: 2 \t Loss: 0.016149559070152465 \t Accuracy: 94.9000015258789\n",
            "model saves at 94.9000015258789 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.027000587501873573 \t Accuracy: 1580.8333740234375\n",
            "Train Epoch: 3 \t Loss: 0.013856406901730225 \t Accuracy: 96.20000457763672\n",
            "model saves at 96.20000457763672 accuracy\n",
            "Train Epoch: 4 \t Loss: 0.019541306355968117 \t Accuracy: 1607.0\n",
            "Train Epoch: 4 \t Loss: 0.010730128669732948 \t Accuracy: 96.9000015258789\n",
            "model saves at 96.9000015258789 accuracy\n",
            "Train Epoch: 5 \t Loss: 0.01950209471397102 \t Accuracy: 1608.3333740234375\n",
            "Train Epoch: 5 \t Loss: 0.010260237032081931 \t Accuracy: 97.20000457763672\n",
            "model saves at 97.20000457763672 accuracy\n",
            "Train Epoch: 6 \t Loss: 0.015179856178971628 \t Accuracy: 1618.666748046875\n",
            "Train Epoch: 6 \t Loss: 0.009976471926638624 \t Accuracy: 96.60000610351562\n",
            "Train Epoch: 7 \t Loss: 0.01440004312278082 \t Accuracy: 1625.166748046875\n",
            "Train Epoch: 7 \t Loss: 0.008544882228859933 \t Accuracy: 97.10000610351562\n",
            "Train Epoch: 8 \t Loss: 0.011785667422227562 \t Accuracy: 1632.5\n",
            "Train Epoch: 8 \t Loss: 0.0090714324953733 \t Accuracy: 97.30000305175781\n",
            "model saves at 97.30000305175781 accuracy\n",
            "Train Epoch: 9 \t Loss: 0.01337209123885259 \t Accuracy: 1625.3333740234375\n",
            "Train Epoch: 9 \t Loss: 0.010185060097253881 \t Accuracy: 97.00000762939453\n",
            "Train Epoch: 10 \t Loss: 0.010865889517202352 \t Accuracy: 1631.8333740234375\n",
            "Train Epoch: 10 \t Loss: 0.006919232880594791 \t Accuracy: 97.30000305175781\n",
            "None\n",
            "(array([1, 3, 5, 5, 0, 2, 3, 8, 4, 8]), array([1, 3, 5, 5, 0, 2, 3, 8, 4, 8]))\n",
            "[INFO] model resnext101_32x8d is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.13180438488721846 \t Accuracy: 1274.0\n",
            "Train Epoch: 1 \t Loss: 0.02589382228907198 \t Accuracy: 91.30000305175781\n",
            "model saves at 91.30000305175781 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.03445975453903278 \t Accuracy: 1558.666748046875\n",
            "Train Epoch: 2 \t Loss: 0.01869965981505811 \t Accuracy: 94.20000457763672\n",
            "model saves at 94.20000457763672 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.02345594413888951 \t Accuracy: 1596.0\n",
            "Train Epoch: 3 \t Loss: 0.010859120193097625 \t Accuracy: 96.30000305175781\n",
            "model saves at 96.30000305175781 accuracy\n",
            "Train Epoch: 4 \t Loss: 0.017605982376262545 \t Accuracy: 1615.3333740234375\n",
            "Train Epoch: 4 \t Loss: 0.01129216315256781 \t Accuracy: 97.20000457763672\n",
            "model saves at 97.20000457763672 accuracy\n",
            "Train Epoch: 5 \t Loss: 0.01618719151709229 \t Accuracy: 1618.5\n",
            "Train Epoch: 5 \t Loss: 0.009068607744498877 \t Accuracy: 96.9000015258789\n",
            "Train Epoch: 6 \t Loss: 0.013181602795763562 \t Accuracy: 1626.666748046875\n",
            "Train Epoch: 6 \t Loss: 0.008287348440931964 \t Accuracy: 97.4000015258789\n",
            "model saves at 97.4000015258789 accuracy\n",
            "Train Epoch: 7 \t Loss: 0.013959195541683584 \t Accuracy: 1626.0\n",
            "Train Epoch: 7 \t Loss: 0.014858113737158419 \t Accuracy: 96.10000610351562\n",
            "Train Epoch: 8 \t Loss: 0.012213472238120934 \t Accuracy: 1630.8333740234375\n",
            "Train Epoch: 8 \t Loss: 0.00862312071348424 \t Accuracy: 97.20000457763672\n",
            "Train Epoch: 9 \t Loss: 0.009566184659100448 \t Accuracy: 1636.166748046875\n",
            "Train Epoch: 9 \t Loss: 0.005841440650285221 \t Accuracy: 98.20000457763672\n",
            "model saves at 98.20000457763672 accuracy\n",
            "Train Epoch: 10 \t Loss: 0.010217633092931161 \t Accuracy: 1635.666748046875\n",
            "Train Epoch: 10 \t Loss: 0.009038192675885511 \t Accuracy: 97.60000610351562\n",
            "None\n",
            "(array([4, 8, 1, 7, 9, 1, 1, 9, 2, 2]), array([4, 8, 1, 7, 9, 1, 1, 9, 2, 2]))\n",
            "[INFO] model wide_resnet50_2 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.09329896363119285 \t Accuracy: 1395.3333740234375\n",
            "Train Epoch: 1 \t Loss: 0.02099585716763977 \t Accuracy: 94.80000305175781\n",
            "model saves at 94.80000305175781 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.028271044492721557 \t Accuracy: 1583.8333740234375\n",
            "Train Epoch: 2 \t Loss: 0.021592713910620658 \t Accuracy: 92.70000457763672\n",
            "Train Epoch: 3 \t Loss: 0.020151767500986656 \t Accuracy: 1606.166748046875\n",
            "Train Epoch: 3 \t Loss: 0.008761779478227254 \t Accuracy: 97.30000305175781\n",
            "model saves at 97.30000305175781 accuracy\n",
            "Train Epoch: 4 \t Loss: 0.0157712310180068 \t Accuracy: 1620.3333740234375\n",
            "Train Epoch: 4 \t Loss: 0.0121469306092622 \t Accuracy: 96.70000457763672\n",
            "Train Epoch: 5 \t Loss: 0.013372738858452067 \t Accuracy: 1625.666748046875\n",
            "Train Epoch: 5 \t Loss: 0.013518414844875225 \t Accuracy: 95.4000015258789\n",
            "Train Epoch: 6 \t Loss: 0.011831692331858601 \t Accuracy: 1631.166748046875\n",
            "Train Epoch: 6 \t Loss: 0.005348783700592321 \t Accuracy: 98.80000305175781\n",
            "model saves at 98.80000305175781 accuracy\n",
            "Train Epoch: 7 \t Loss: 0.010426683226445068 \t Accuracy: 1637.166748046875\n",
            "Train Epoch: 7 \t Loss: 0.006301080434088362 \t Accuracy: 97.70000457763672\n",
            "Train Epoch: 8 \t Loss: 0.010551943632696445 \t Accuracy: 1635.5\n",
            "Train Epoch: 8 \t Loss: 0.0038351161685495753 \t Accuracy: 98.70000457763672\n",
            "Train Epoch: 9 \t Loss: 0.009553694325344015 \t Accuracy: 1639.166748046875\n",
            "Train Epoch: 9 \t Loss: 0.003473918271240109 \t Accuracy: 99.10000610351562\n",
            "model saves at 99.10000610351562 accuracy\n",
            "Train Epoch: 10 \t Loss: 0.009656506817943106 \t Accuracy: 1638.666748046875\n",
            "Train Epoch: 10 \t Loss: 0.005979487883683759 \t Accuracy: 98.30000305175781\n",
            "None\n",
            "(array([6, 1, 7, 7, 2, 0, 2, 0, 5, 0]), array([6, 1, 7, 7, 2, 0, 2, 0, 5, 0]))\n",
            "[INFO] model wide_resnet101_2 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.133651684820652 \t Accuracy: 1283.166748046875\n",
            "Train Epoch: 1 \t Loss: 0.025627100786194207 \t Accuracy: 91.70000457763672\n",
            "model saves at 91.70000457763672 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.030819462245951095 \t Accuracy: 1571.0\n",
            "Train Epoch: 2 \t Loss: 0.026209202903846745 \t Accuracy: 92.4000015258789\n",
            "model saves at 92.4000015258789 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.023349659175922473 \t Accuracy: 1596.166748046875\n",
            "Train Epoch: 3 \t Loss: 0.01152128021453973 \t Accuracy: 95.80000305175781\n",
            "model saves at 95.80000305175781 accuracy\n",
            "Train Epoch: 4 \t Loss: 0.01878846090597411 \t Accuracy: 1612.0\n",
            "Train Epoch: 4 \t Loss: 0.006835651341301855 \t Accuracy: 98.00000762939453\n",
            "model saves at 98.00000762939453 accuracy\n",
            "Train Epoch: 5 \t Loss: 0.01464784419319282 \t Accuracy: 1622.5\n",
            "Train Epoch: 5 \t Loss: 0.00954407592501957 \t Accuracy: 97.30000305175781\n",
            "Train Epoch: 6 \t Loss: 0.013146155933694293 \t Accuracy: 1627.666748046875\n",
            "Train Epoch: 6 \t Loss: 0.008798503494901525 \t Accuracy: 97.10000610351562\n",
            "Train Epoch: 7 \t Loss: 0.013152924925088882 \t Accuracy: 1628.166748046875\n",
            "Train Epoch: 7 \t Loss: 0.008538713877962437 \t Accuracy: 97.60000610351562\n",
            "Train Epoch: 8 \t Loss: 0.010384251282860836 \t Accuracy: 1636.166748046875\n",
            "Train Epoch: 8 \t Loss: 0.00608264242246878 \t Accuracy: 98.70000457763672\n",
            "model saves at 98.70000457763672 accuracy\n",
            "Train Epoch: 9 \t Loss: 0.010660172186714287 \t Accuracy: 1637.0\n",
            "Train Epoch: 9 \t Loss: 0.009333821817912395 \t Accuracy: 96.60000610351562\n",
            "Train Epoch: 10 \t Loss: 0.010271590164241692 \t Accuracy: 1638.0\n",
            "Train Epoch: 10 \t Loss: 0.009520777961133717 \t Accuracy: 97.4000015258789\n",
            "None\n",
            "(array([1, 7, 2, 1, 5, 1, 2, 3, 9, 0]), array([1, 7, 2, 1, 5, 1, 2, 3, 9, 0]))\n",
            "[INFO] model shufflenet_v2_x0_5 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.2659641921520233 \t Accuracy: 740.8333740234375\n",
            "Train Epoch: 1 \t Loss: 0.09814320561289787 \t Accuracy: 67.10000610351562\n",
            "model saves at 67.10000610351562 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.13494949623942376 \t Accuracy: 1205.8333740234375\n",
            "Train Epoch: 2 \t Loss: 0.0571934104077518 \t Accuracy: 80.50000762939453\n",
            "model saves at 80.50000762939453 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.0949060677488645 \t Accuracy: 1357.5\n",
            "Train Epoch: 3 \t Loss: 0.04168372318893671 \t Accuracy: 85.60000610351562\n",
            "model saves at 85.60000610351562 accuracy\n",
            "Train Epoch: 4 \t Loss: 0.06921490550041198 \t Accuracy: 1441.666748046875\n",
            "Train Epoch: 4 \t Loss: 0.03352353026717901 \t Accuracy: 90.10000610351562\n",
            "model saves at 90.10000610351562 accuracy\n",
            "Train Epoch: 5 \t Loss: 0.05790671057999134 \t Accuracy: 1484.666748046875\n",
            "Train Epoch: 5 \t Loss: 0.027203311081044377 \t Accuracy: 91.70000457763672\n",
            "model saves at 91.70000457763672 accuracy\n",
            "Train Epoch: 6 \t Loss: 0.04768474226196607 \t Accuracy: 1517.0\n",
            "Train Epoch: 6 \t Loss: 0.019898751760134472 \t Accuracy: 93.70000457763672\n",
            "model saves at 93.70000457763672 accuracy\n",
            "Train Epoch: 7 \t Loss: 0.03950430292636156 \t Accuracy: 1542.3333740234375\n",
            "Train Epoch: 7 \t Loss: 0.02402887322753668 \t Accuracy: 92.9000015258789\n",
            "Train Epoch: 8 \t Loss: 0.03579488888382912 \t Accuracy: 1553.666748046875\n",
            "Train Epoch: 8 \t Loss: 0.021263214030535892 \t Accuracy: 93.9000015258789\n",
            "model saves at 93.9000015258789 accuracy\n",
            "Train Epoch: 9 \t Loss: 0.03309394459550579 \t Accuracy: 1566.666748046875\n",
            "Train Epoch: 9 \t Loss: 0.016413645472261124 \t Accuracy: 94.70000457763672\n",
            "model saves at 94.70000457763672 accuracy\n",
            "Train Epoch: 10 \t Loss: 0.030575235014160474 \t Accuracy: 1569.3333740234375\n",
            "Train Epoch: 10 \t Loss: 0.017864994132658466 \t Accuracy: 94.60000610351562\n",
            "None\n",
            "(array([4, 6, 1, 4, 2, 0, 9, 9, 2, 8]), array([4, 6, 1, 4, 2, 0, 9, 9, 2, 8]))\n",
            "[INFO] model shufflenet_v2_x1_0 is training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \t Loss: 0.1800223126510779 \t Accuracy: 1050.166748046875\n",
            "Train Epoch: 1 \t Loss: 0.06022643058747053 \t Accuracy: 81.4000015258789\n",
            "model saves at 81.4000015258789 accuracy\n",
            "Train Epoch: 2 \t Loss: 0.07055695553620657 \t Accuracy: 1444.666748046875\n",
            "Train Epoch: 2 \t Loss: 0.02615567321050912 \t Accuracy: 91.70000457763672\n",
            "model saves at 91.70000457763672 accuracy\n",
            "Train Epoch: 3 \t Loss: 0.04759706981480122 \t Accuracy: 1521.5\n",
            "Train Epoch: 3 \t Loss: 0.023794734659139068 \t Accuracy: 92.80000305175781\n",
            "model saves at 92.80000305175781 accuracy\n",
            "Train Epoch: 4 \t Loss: 0.03962802482148012 \t Accuracy: 1544.3333740234375\n",
            "Train Epoch: 4 \t Loss: 0.019635121732717378 \t Accuracy: 93.20000457763672\n",
            "model saves at 93.20000457763672 accuracy\n",
            "Train Epoch: 5 \t Loss: 0.03206874698400498 \t Accuracy: 1571.0\n",
            "Train Epoch: 5 \t Loss: 0.014337650439469144 \t Accuracy: 94.70000457763672\n",
            "model saves at 94.70000457763672 accuracy\n",
            "Train Epoch: 6 \t Loss: 0.028822665543605883 \t Accuracy: 1582.3333740234375\n",
            "Train Epoch: 6 \t Loss: 0.014523729019099846 \t Accuracy: 95.4000015258789\n",
            "model saves at 95.4000015258789 accuracy\n",
            "Train Epoch: 7 \t Loss: 0.023737100266541043 \t Accuracy: 1594.5\n",
            "Train Epoch: 7 \t Loss: 0.013851042314898223 \t Accuracy: 95.4000015258789\n",
            "Train Epoch: 8 \t Loss: 0.022413273913164933 \t Accuracy: 1593.0\n",
            "Train Epoch: 8 \t Loss: 0.011597649262053892 \t Accuracy: 95.9000015258789\n",
            "model saves at 95.9000015258789 accuracy\n",
            "Train Epoch: 9 \t Loss: 0.02151556184825798 \t Accuracy: 1604.666748046875\n",
            "Train Epoch: 9 \t Loss: 0.006798519170726649 \t Accuracy: 97.80000305175781\n",
            "model saves at 97.80000305175781 accuracy\n",
            "Train Epoch: 10 \t Loss: 0.01950102494719128 \t Accuracy: 1609.3333740234375\n",
            "Train Epoch: 10 \t Loss: 0.013757930378022138 \t Accuracy: 96.4000015258789\n",
            "None\n",
            "(array([8, 8, 4, 7, 4, 7, 2, 2, 9, 9]), array([8, 8, 4, 7, 4, 7, 2, 2, 9, 9]))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}