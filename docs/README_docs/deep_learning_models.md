# List of papers related 

## 

## VAE

## 2020

Draft and Edit: Automatic Storytelling Through Multi-Pass Hierarchical Conditional Variational Autoencoder. Yu, Li, Liu, Tang, Zhang, Zhao, Yan https://www.aaai.org/Papers/AAAI/2020GB/AAAI-YuM.8133.pdf

Reverse variational autoencoder for visual attribute manipulation and anomaly detection.  Gauerhof, Gu  http://openaccess.thecvf.com/content_WACV_2020/papers/Lydia_Reverse_Variational_Autoencoder_for_Visual_Attribute_Manipulation_and_Anomaly_Detection_WACV_2020_paper.pdf


Bridged variational autoencoders for joint modeling of images and attributes. Yadav, Sarana, Namboodiri, Hegde  http://openaccess.thecvf.com/content_WACV_2020/papers/Yadav_Bridged_Variational_Autoencoders_for_Joint_Modeling_of_Images_and_Attributes_WACV_2020_paper.pdf


Treatment effect estimation with disentangled latent factors. anon  https://arxiv.org/abs/2001.10652

Unbalanced GANS: pre-training the generator of generative adversarial network using variational autoencoder.  Ham, Jun, Kim https://arxiv.org/pdf/2002.02112.pdf

Regularized autoencoders via relaxed injetive probability flow. Kumar, Poole, Murphy  https://arxiv.org/abs/2002.08927

Out-of-distribution detection with distance guarantee in deep generative models.  Zhang, Liu, Chen, Wang, Liu, Li, Wei, Chen  https://arxiv.org/abs/2002.03328

Balancing reconstruction error and Kullback-Leibler divergence in variational autoencoders. Asperti, Trentin  https://arxiv.org/pdf/2002.07514.pdf

Data augmentation for historical documents via cascade variational auto-encoder.  Cao, Kamata https://ieeexplore.ieee.org/abstract/document/8977737

Controlling generative models with continuous factors of variations.  Plumerault, Borgne, Hudelot https://arxiv.org/pdf/2001.10238.pdf

Towards a controllable disentanglement network. Song, Koyejo, Zhang https://arxiv.org/abs/2001.08572

Knowledge-induced learning with adaptive sampling variational autoencoders for open set fault diagnostics.  Chao, Adey, Fink  https://arxiv.org/abs/1912.12502

NestedVAE: isolating common factors via weak supervision. Vowels, Camgoz, Bowden   https://arxiv.org/abs/2002.11576

Leveraging cross feedback of user and item embeddings for variational autoencoder based collaborative filtering.  Jin, Zhao, Du, Liu, Gao, Li, Xu https://arxiv.org/pdf/2002.09145.pdf

K-autoencoders deep clustering. Opochinsky, Chazan, Gannot, Goldberger  http://www.eng.biu.ac.il/goldbej/files/2020/02/ICASSP_2020_Yaniv.pdf

D2D-TM: a cycle VAE-GAN for multi-domain collaborative filtering. Nguyen, Ishigaki  https://ieeexplore.ieee.org/abstract/document/9006461/

Disentangling controllable object through video prediction improves visual reinforcement learning.  Zhong, Schwing, Peng  https://arxiv.org/pdf/2002.09136.pdf

A deep adversarial variational autoencoder model for dimensionality reduction in single-cell RNA sequencing analysis. Lin, Mukherjee, Kannan  https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-020-3401-5

Context conditional variational autoencoder for predicting multi-path trajectories in mixed traffic.  Cheng, Liao, Yang, Sester, Rosenhahn  https://arxiv.org/pdf/2002.05966.pdf

Optimizing variational graph autoencoder for community detection with dual optimization.  Choong, Liu, Murata 

Learning flat latent manifolds with VAEs. Chen, Klushyn, Ferroni, Bayer, van der Smagt  https://arxiv.org/pdf/2002.04881.pdf

Learning discrete distributions by dequantization.  Hoogeboom, Cohen, Tomczak https://arxiv.org/pdf/2001.11235.pdf

Learning discrete and continuous factors of data via alternating disentanglement. Jeong, Song http://proceedings.mlr.press/v97/jeong19d/jeong19d.pdf https://github.com/snu-mllab/DisentanglementICML19


Electrocardiogram generation and feature extraction using a variational autoencoder. Kuznetsov, Moskalenko, Zolotykh  https://arxiv.org/pdf/2002.00254.pdf

CosmoVAE: variational autoencoder for CMB image inpainting. Yi, Guo, Fan, Hamann, Wang  https://arxiv.org/pdf/2001.11651.pdf

Unsupervised representation disentanglement using cross domain features and adversarial learning in variational autoencoder based voice conversion. Huang, Luo, Hwang, Lo, Peng, Tsao, Wang https://arxiv.org/pdf/2001.07849.pdf

On implicit regularization in beta VAEs.  Kumar, Poole  https://arxiv.org/pdf/2002.00041.pdf

Weakly-supervised disentanglement without compromises.  Locatello, Poole, Ratsch, Scholkopf, Bachem, Tschannen  https://arxiv.org/pdf/2002.02886.pdf


An integrated framework based on latent variational autoencoder for providing early warning of at-risk students.  Du, Yang, Hung  https://ieeexplore.ieee.org/abstract/document/8952699

Variational autoencoder and friends.  Zheng https://www.cs.cmu.edu/~xunzheng/files/vae_single.pdf

High-fidelity synthesis with disentangled representation. Lee, Kim, Hong, Lee https://arxiv.org/pdf/2001.04296.pdf

Neurosymbolic knowledge representation for explainable and trustworthy AI.  Malo  https://www.preprints.org/manuscript/202001.0163/v1

Adversarial disentanglement with grouped observations.  Nemeth  https://arxiv.org/pdf/2001.04761.pdf

AE-OT-GAN: Training GANs from data specific latent distribution.  An, Guo, Zhang, Qi, Lei, Yau, Gu  https://arxiv.org/pdf/2001.03698.pdf

AE-OT: a new generative model based on extended semi-discrete optimal transport.  An, Guo, Lei, Luo, Yau, Gu  https://openreview.net/pdf?id=HkldyTNYwH

Disentanglement by nonlinear ICA with general incompressible-flow networks (GIN). Sorrenson, Rother, Kothe  https://arxiv.org/pdf/2001.04872.pdf

Phase transitions for the information bottleneck in representation learning.  Wu, Fischer https://arxiv.org/pdf/2001.01878.pdf

Bayesian deep learning: a model-based interpretable approach.   Matsubara https://www.jstage.jst.go.jp/article/nolta/11/1/11_16/_article

SPACE: unsupervised object-oriented scene representation via spatial attention and decomposition.   Lin, Wu, Peri, Sun, Singh, Deng, Jiang, Ahn https://openreview.net/forum?id=rkl03ySYDH

A variational stacked autoencoder with harmony search optimizer for valve train fault diagnosis of diesel engine. Chen, Mao, Zhao, Jiang, Zhang https://www.mdpi.com/1424-8220/20/1/223

Evaluating loss compression rates of deep generative models.  anon  https://openreview.net/forum?id=ryga2CNKDH

Progressive learning and disentanglement of hierarchical representations.  anon https://openreview.net/forum?id=SJxpsxrYPS

Learning group structure and disentangled representations of dynamical environments.  Quessard, Barrett, Clements https://arxiv.org/abs/2002.06991

A simple framework for contrastive learning of visual representations.  Chen, Kornblith, Norouzi, Hinton  https://arxiv.org/abs/2002.05709


##VAE Lok Raj
WiSE-ALE: Wide Sample Estimator for Approximate Latent Embedding. Shuyu Lin, Ronald Clark, Robert Birke, Niki Trigoni, Stephen Roberts https://arxiv.org/pdf/1902.06160.pdf

Learning to Dress 3D People in Generative Clothing. Qianli Ma, Jinlong Yang, Anurag Ranjan, Sergi Pujades, Gerard Pons-Moll, Siyu Tang, Michael J. Black https://arxiv.org/pdf/1907.13615.pdf

VV-Net: Voxel VAE Net With Group Convolutions for Point Cloud Segmentation. Hsien-Yu Meng, Lin Gao, Yu-Kun Lai, Dinesh Manocha http://openaccess.thecvf.com/content_ICCV_2019/papers/Meng_VV-Net_Voxel_VAE_Net_With_Group_Convolutions_for_Point_Cloud_ICCV_2019_paper.pdf
## 2019

Disentangling and learning robust representations with naturual clustering  . Antoran, Miguel https://arxiv.org/abs/1901.09415

Inherent tradeoffs in learning fair representations.  Zhao, Gordon  https://arxiv.org/abs/1906.08386

Affine variational autoencoders: an efficient approach for improving generalization and robustness to distribution shift. Bidart, Wong  https://arxiv.org/pdf/1905.05300.pdf

Learning deep controllable and structured representations for image synthesis, structured prediction and beyond.  Yan https://deepblue.lib.umich.edu/handle/2027.42/153334


Continual unsupervised representation learning  . Rao, Visin, Rusu, The, Pascanu, Hadsell  https://arxiv.org/pdf/1910.14481.pdf

Group-based learning of disentangled representations with generalizability for novel contents.  Hosoya  https://www.ijcai.org/Proceedings/2019/0348.pdf

Task-Conditioned variational autoencoders for learning movement primitives. Noseworthy, Paul, Roy, Park, Roy  https://groups.csail.mit.edu/rrg/papers/noseworthy_corl_19.pdf

Multimodal generative models for compositional representation learning. Wu, Goodman https://arxiv.org/pdf/1912.05075.pdf

dpVAEs: fixing sample generation for regularized VAEs.  Bhalodia, Lee, Elhabian https://arxiv.org/pdf/1911.10506.pdf

From variational to deterministic autoencoders.   Ghosh, Sajjadi, Vergai, Black, Scholkopf  https://arxiv.org/pdf/1903.12436.pdf

Learning representations by maximizing mutual information in variational autoencoder. Rezaabad, Vishwanath  https://arxiv.org/pdf/1912.13361.pdf  

Disentangled representation learning with Wasserstein total correlation.  Xiao, Wang  https://arxiv.org/pdf/1912.12818.pdf  

Wasserstein dependency measure for representation learning.   Ozair, Lynch, Bengio, van den Oord, Levine, Sermanent https://arxiv.org/pdf/1903.11780.pdf  

GP-VAE: deep probabilistic time series imputation.  Fortuin, Baranchuk, Ratsch, Mandt https://arxiv.org/pdf/1907.04155.pdf  https://github.com/ratschlab/GP-VAE

Likelihood contribution based multi-scale architecture for generative flows.  Das, Abbeel, Spanos  https://arxiv.org/pdf/1908.01686.pdf 

Gated Variational Autoencoders: Incorporating weak supervision to encourage disentanglement.  Vowels, Camgoz, Bowden   https://arxiv.org/pdf/1911.06443.pdf 

An introduction to variational autoencoders.  Kingma, Welling https://arxiv.org/pdf/1906.02691.pdf

Adaptive density estimation for generative models Lucas, Shmelkov, Schmid, Alahari, Verbeek https://papers.nips.cc/paper/9370-adaptive-density-estimation-for-generative-models.pdf

Data efficient mutual information neural estimator  Lin, Sur, Nastase, Divakaran, Hasson, Amer  https://arxiv.org/pdf/1905.03319.pdf

RecVAE: a new variational autoencoder for Top-N recommendations with implicit feedback. Shenbin, Alekseev, Tutubalina, Malykh, Nikolenko  https://arxiv.org/pdf/1912.11160.pdf

Vibration signal generation using conditional variational autoencoder for class imbalance problem.  Ko, Kim, Kong, Lee, Youn  http://icmr2019.ksme.or.kr/wp/pdf/190090.pdf

The usual suspects? Reassessing blame for VAE posterior collapse.   Dai, Wang, Wipf https://arxiv.org/pdf/1912.10702.pdf

What does the free energy principle tell us about the brain?  Gershman  https://arxiv.org/pdf/1901.07945.pdf

Sub-band vector quantized variational autoencoder for spectral envelope quantization. Srikotr, Mano https://ieeexplore.ieee.org/abstract/document/8929436 

A variational-sequential graph autoencoder for neural performance prediction. Friede, Lukasik, Stuckenschmidt, Keuper https://arxiv.org/pdf/1912.05317.pdf  

Explicit disentanglement of appearance and perspective in generative models.  Skafte, Hauberg https://papers.nips.cc/paper/8387-explicit-disentanglement-of-appearance-and-perspective-in-generative-models.pdf 

Disentangled behavioural representations. Dezfouli, Ashtiani, Ghattas, Nock, Dayan, Ong https://papers.nips.cc/paper/8497-disentangled-behavioural-representations.pdf  

Learning disentangled representations for robust person re-identification.  Eom, Ham  https://papers.nips.cc/paper/8771-learning-disentangled-representation-for-robust-person-re-identification.pdf  

Towards latent space optimality for auto-encoder based generative models. Mondal, Chowdhury, Jayendran, Singla, Asnani, AP  https://arxiv.org/pdf/1912.04564.pdf  

Don't blame the ELBO! A linear VAE perspective on posterior collapse. Lucas, Tucker, Grosse, Norouzi  https://128.84.21.199/pdf/1911.02469.pdf

Bridging the ELBO and MMD.  Ucar  https://arxiv.org/pdf/1910.13181.pdf

Learning disentangled representations for counterfactual regression.  Hassanpour, Greiner https://pdfs.semanticscholar.org/1df4/204e14da51b05a14781e2a4dc3e0d7da562d.pdf

Learning disentangled representations for recommendation. Ma, Zhou, Cui, Yang, Zhu  https://arxiv.org/pdf/1910.14238.pdf

A vector quantized variational autoencoder (VQ-VAE) autoregressive neural F0 model for statistical parametric speech synthesis. Wang, Takaki, Yamagishi, King, Tokuda https://ieeexplore.ieee.org/abstract/document/8884734

Diversity-aware event prediction based on a conditional variational autoencoder with reconstruction.  Kiyomaru, Omura, Murawaki, Kawahara, Kurohashi  https://www.aclweb.org/anthology/D19-6014.pdf

Learning multimodal representations with factorized deep generative models. Tsai, Liang, Zadeh, Morency, Salakhutdinov  https://pdfs.semanticscholar.org/7416/6384ad391513e8e8bf48cbeaff2516b8c332.pdf

High-dimensional nonlinear profile monitoring based on deep probabilistic autoencoders. Sergin, Yan https://arxiv.org/pdf/1911.00482.pdf

Leveraging directed causal discovery to detect latent common causes.  Lee, Hart, Richens, Johri https://arxiv.org/pdf/1910.10174.pdf

Robust discrimination and generation of faces using compact, disentangled embeddings. Browatzki, Wallraven  http://openaccess.thecvf.com/content_ICCVW_2019/papers/RSL-CV/Browatzki_Robust_Discrimination_and_Generation_of_Faces_using_Compact_Disentangled_Embeddings_ICCVW_2019_paper.pdf

Coulomb Autoencoders. Sansone, Ali, Sun https://arxiv.org/pdf/1802.03505.pdf

Contrastive learning of structured world models.  Kipf, Pol, Welling  https://arxiv.org/pdf/1911.12247.pdf

No representation without transformation. Giannone, Masci, Osendorfer https://pgr-workshop.github.io/img/PGR007.pdf

Neural density estimation.  Papamakarios  https://arxiv.org/pdf/1910.13233.pdf

Variational autoencoder-based approach for rail defect identification.  Wei, Ni http://www.dpi-proceedings.com/index.php/shm2019/article/view/32432

Variational learning with disentanglement-pytorch.  Abdi, Abolmaesumi, Fels https://openreview.net/pdf?id=rJgUsFYnir

PVAE: learning disentangled representations with intrinsic dimension via approximated L0 regularization.  Shi, Glocker, Castro  https://openreview.net/pdf?id=HJg8stY2oB

Mixed-curvature variational autoencoders.   Skopek, Ganea, Becigneul  https://arxiv.org/pdf/1911.08411.pdf

Continuous hierarchical representations with poincare variational autoencoders.   Mathieu, Le Lan, Maddison, Tomioka  https://arxiv.org/pdf/1901.06033.pdf

VIREL: A variational inference framework for reinforcement learning.  Fellows, Mahajan, Rudner, Whiteson  https://arxiv.org/pdf/1811.01132.pdf

Disentangling video with independent prediction.  Whitney, Fergus https://arxiv.org/pdf/1901.05590.pdf

Disentangling state space representations Miladinovic, Gondal, Scholkopf, Buhmann, Bauer  https://arxiv.org/pdf/1906.03255.pdf

Likelihood conribution based multi-scale architecture for generative flows. Das, Abbeel, Spanos https://arxiv.org/pdf/1908.01686.pdf

AlignFlow: cycle consistent learning from multiple domains via normalizing flows  Grover, Chute, Shu, Cao, Ermon  https://arxiv.org/pdf/1905.12892.pdf


IB-GAN: disentangled representation learning with information bottleneck GAN.   Jeon, Lee, Kim  https://openreview.net/forum?id=ryljV2A5KX

Learning hierarchical priors in VAEs.  Klushyn, Chen, Kurle, Cseke, van der Smagt https://papers.nips.cc/paper/8553-learning-hierarchical-priors-in-vaes.pdf

ODE2VAE: Deep generative second order ODEs with Bayesian neural networks. Yildiz, Heinonen, Lahdesmaki  https://papers.nips.cc/paper/9497-ode2vae-deep-generative-second-order-odes-with-bayesian-neural-networks.pdf

Explicitly disentangling image content from translation and rotation with spatial-VAE.  Bepler, Zhong, Kelley, Brignole, Berger https://papers.nips.cc/paper/9677-explicitly-disentangling-image-content-from-translation-and-rotation-with-spatial-vae.pdf

A primal-dual link between GANs and autoencoders. Husain, Nock, Williamson  https://papers.nips.cc/paper/8333-a-primal-dual-link-between-gans-and-autoencoders.pdf

Exact rate-distortion in autoencoders via echo noise. Brekelmans, Moyer, Galstyan, ver Steeg  https://papers.nips.cc/paper/8644-exact-rate-distortion-in-autoencoders-via-echo-noise.pdf

Direct optimization through arg max for discrete variational auto-encoder.  Lorberbom, Jaakkola, Gane, Hazan  https://papers.nips.cc/paper/8851-direct-optimization-through-arg-max-for-discrete-variational-auto-encoder.pdf

Semi-implicit graph variational auto-encoders.  Hasanzadeh, Hajiramezanali, Narayanan, Duffield, Zhou, Qian https://papers.nips.cc/paper/9255-semi-implicit-graph-variational-auto-encoders.pdf

The continuous Bernoulli: fixing a pervasive error in variational autoencoders. Loaiza-Ganem, Cunningham  https://papers.nips.cc/paper/9484-the-continuous-bernoulli-fixing-a-pervasive-error-in-variational-autoencoders.pdf

Provable gradient variance guarantees for black-box variational inference.  Domke https://papers.nips.cc/paper/8325-provable-gradient-variance-guarantees-for-black-box-variational-inference.pdf

Conditional structure generation through graph variational generative adversarial nets. Yang, Zhuang, Shi, Luu, Li  https://papers.nips.cc/paper/8415-conditional-structure-generation-through-graph-variational-generative-adversarial-nets.pdf

Scalable spike source localization in extracellular recordings using amortized variational inference. Hurwitz, Xu, Srivastava, Buccino, Hennig  https://papers.nips.cc/paper/8720-scalable-spike-source-localization-in-extracellular-recordings-using-amortized-variational-inference.pdf

A latent variational framework for stochastic optimization. Casgrain  https://papers.nips.cc/paper/8802-a-latent-variational-framework-for-stochastic-optimization.pdf

MAVEN: multi-agent variational exploration. Mahajan, Rashid, Samvelyan, Whiteson  https://papers.nips.cc/paper/8978-maven-multi-agent-variational-exploration.pdf

Variational graph recurrent neural networks.  Hajiramezanali, Hasanzadeh, Narayanan, Duffield, Zhou, Qian https://papers.nips.cc/paper/9254-variational-graph-recurrent-neural-networks.pdf

The thermodynamic variational objective.  Masrani, Le, Wood https://papers.nips.cc/paper/9328-the-thermodynamic-variational-objective.pdf

Variational temporal abstraction.   Kim, Ahn, Bengio  https://papers.nips.cc/paper/9332-variational-temporal-abstraction.pdf

Exploiting video sequences for unsupervised disentangling in generative adversarial networks. Tuesca, Uzal  https://arxiv.org/pdf/1910.11104.pdf

Couple-VAE: mitigating the encoder-decoder incompatibility in variational text modeling with coupled deterministic networks.    https://openreview.net/pdf?id=SJlo_TVKwS

Variational mixture-of-experts autoencoders for multi-modal deep generative models. Shi, Siddharth, Paige, Torr https://papers.nips.cc/paper/9702-variational-mixture-of-experts-autoencoders-for-multi-modal-deep-generative-models.pdf

Invertible convolutional flow.  Karami, Schuurmans, Sohl-Dickstein, Dinh, Duckworth https://papers.nips.cc/paper/8801-invertible-convolutional-flow.pdf

Implicit posterior variational inference for deep Gaussian processes. Yu, Chen, Dai, Low, Jaillet https://papers.nips.cc/paper/9593-implicit-posterior-variational-inference-for-deep-gaussian-processes.pdf

MaCow: Masked convolutional generative flow.  Ma, Kong, Zhang, Hovy https://papers.nips.cc/paper/8824-macow-masked-convolutional-generative-flow.pdf

Residual flows for invertible generative modeling.  Chen, Behrmann, Duvenaud, Jacobsen  https://papers.nips.cc/paper/9183-residual-flows-for-invertible-generative-modeling.pdf

Discrete flows: invertible generative models of discrete data.  Tran, Vafa, Agrawal, Dinh, Poole  https://papers.nips.cc/paper/9612-discrete-flows-invertible-generative-models-of-discrete-data.pdf

Re-examination of the role of latent variables in sequence modeling.  Lai, Dai, Yang, Yoo https://papers.nips.cc/paper/8996-re-examination-of-the-role-of-latent-variables-in-sequence-modeling.pdf

Learning-in-the-loop optimization: end-to-end control and co-design of soft robots through learned deep latent representations. Spielbergs, Zhao, Hu, Du, Matusik, Rus  https://papers.nips.cc/paper/9038-learning-in-the-loop-optimization-end-to-end-control-and-co-design-of-soft-robots-through-learned-deep-latent-representations.pdf

Triad constraints for learning causal structure of latent variables.  Cai, Xie, Glymour, Hao, Zhang https://papers.nips.cc/paper/9448-triad-constraints-for-learning-causal-structure-of-latent-variables.pdf

Disentangling influence: using disentangled representations to audit model predictions. Marx, Phillips, Friedler, Scheidegger, Venkatasubramanian https://papers.nips.cc/paper/8699-disentangling-influence-using-disentangled-representations-to-audit-model-predictions.pdf

Symmetry-based disentangled representation learning requires interaction with environments. Caselles-Dupre, Ortiz, Filliat  https://papers.nips.cc/paper/8709-symmetry-based-disentangled-representation-learning-requires-interaction-with-environments.pdf

Weakly supervised disentanglement with guarantees.  Shu, Chen, Kumar, Ermon, Poole  https://arxiv.org/pdf/1910.09772.pdf

Demystifying inter-class disentanglement. Gabbay, Hoshen  https://arxiv.org/pdf/1906.11796.pdf

Spectral regularization for combating mode collapse in GANs.  Liu, Tang, Xie, Qiu https://arxiv.org/pdf/1908.10999.pdf

Geometric disentanglement for generative latent shape models. Aumentado-Armstrong, Tsogkas, Jepson, Dickinson https://arxiv.org/pdf/1908.06386.pdf

Cross-dataset person re-identification via unsupervised pose disentanglement and adaptation.  Li, Lin, Lin, Wang  https://arxiv.org/pdf/1909.09675.pdf

Identity from here, pose from there: self-supervised disentanglement and generation of objects using unlabeled videos.  Xiao, Liu, Lee  https://web.cs.ucdavis.edu/~yjlee/projects/iccv2019_disentangle.pdf

Content and style disentanglement for artistic style transfer.  Kotovenko, Sanakoyeu, Lang, Ommer https://compvis.github.io/content-style-disentangled-ST/paper.pdf

Unsupervised robust disentangling of latent characteristics for image synthesis.  Esser, Haux, Ommer  https://arxiv.org/pdf/1910.10223.pdf

LADN: local adversarial disentangling network for facial makeup and de-makeup.  Gu, Wang, Chiu, Tai, Tang https://arxiv.org/pdf/1904.11272.pdf

Video compression with rate-distortion autoencoders.  Habibian, van Rozendaal, Tomczak, Cohen https://arxiv.org/pdf/1908.05717.pdf

Variable rate deep image compression with a conditional autoencoder.  Choi, El-Khamy, Lee https://arxiv.org/pdf/1909.04802.pdf

Memorizing normality to detect anomaly: memory-augmented deep autoencoder for unsupervised anomaly detection. Gong, Liu, Le, Saha https://arxiv.org/pdf/1904.02639.pdf

AVT: unsupervise d learning of transformation equivariant representations by autoencoding variational transformations.  Qi, Zhang, Chen, Tian https://arxiv.org/pdf/1903.10863.pdf

Deep clustering by Gaussian mixture variational autoencoders with graph embedding.  Yang, Cheung, Li, Fang  http://openaccess.thecvf.com/content_ICCV_2019/papers/Yang_Deep_Clustering_by_Gaussian_Mixture_Variational_Autoencoders_With_Graph_Embedding_ICCV_2019_paper.pdf

Variational adversarial active learning.  Sinha, Ebrahimi, Darrell  https://arxiv.org/pdf/1904.00370.pdf

Variational few-shot learning.  Zhang, Zhao, Ni, Xu, Yang http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Variational_Few-Shot_Learning_ICCV_2019_paper.pdf

Multi-angle point cloud-VAE: unsupervised feature learning for 3D point clouds from multiple angles by joint self-reconstruction and half-to-half prediction. Han, Wang, Liu, Zwicker https://arxiv.org/pdf/1907.12704.pdf

LayoutVAE: stochastic scene layout generation from a label set.  Jyothi, Durand, He, Sigal, Mori  https://arxiv.org/pdf/1907.10719.pdf

VV-NET: Voxel VAE Net with group convolutions for point cloud segmentation. Meng, Gao, Lai, Manocha https://arxiv.org/pdf/1811.04337.pdf

Bayes-Factor-VAE: hierarchical bayesian deep auto-encoder models for factor disentanglement.  Kim, Wang, Sahu, Pavlovic https://arxiv.org/pdf/1909.02820.pdf


Robust ordinal VAE: Employing noisy pairwise comparisons for disentanglement. Chen, Batmanghelich https://arxiv.org/pdf/1910.05898.pdf

Evaluating disentangled representations.  Sepliarskaia, A. and Kiseleva, J. and de Rijke, M.  https://arxiv.org/pdf/1910.05587.pdf

A stable variational autoencoder for text modelling.  Li, R. and Li, X. and Lin, C. and Collinson, M. and Mao, R. https://abdn.pure.elsevier.com/en/publications/a-stable-variational-autoencoder-for-text-modelling

Hamiltonian generative networks.  Toth, Rezende, Jaegle, Racaniere, Botev, Higgins  https://128.84.21.199/pdf/1909.13789.pdf

LAVAE: Disentangling location and appearance. Dittadi, Winther  https://arxiv.org/pdf/1909.11813.pdf

Interpretable models in probabilistic machine learning. Kim https://ora.ox.ac.uk/objects/uuid:b238ed7d-7155-4860-960e-6227c7d688fb/download_file?file_format=pdf&safe_filename=PhD_Thesis_of_University_of_Oxford.pdf&type_of_work=Thesis


Disentangling speech  and non-speech components for building robust acoustic models from found data.  Gurunath, Rallabandi, Black https://arxiv.org/pdf/1909.11727.pdf

Joint separation, dereverberation and classification of multiple sources using multichannel variational autoencoder with auxiliary classifier.  Inoue, Kameoka, Li, Makino  http://pub.dega-akustik.de/ICA2019/data/articles/000906.pdf

SuperVAE: Superpixelwise variational autoencoder for salient object detection.  Li, Sun, Guo  https://www.aaai.org/ojs/index.php/AAAI/article/view/4876

Implicit discriminator in variational autoencoder.  Munjal, Paul, Krishnan  https://arxiv.org/pdf/1909.13062.pdf

TransGaGa: Geometry-aware unsupervised image-to-image translation.  Wu, Cao, Li, Qian, Loy  http://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_TransGaGa_Geometry-Aware_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.pdf

Variational attention using articulatory priors for generating code mixed speech using monolingual corpora. Rallabandi, Black.  https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1103.pdf

One-class collaborative filtering with the queryable variational autoencoder. Wu, Bouadjenek, Sanner. https://people.eng.unimelb.edu.au/mbouadjenek/papers/SIGIR_Short_2019.pdf

Predictive auxiliary variational autoencoder for representation learning of global speech characteristics.  Springenberg, Lakomkin, Weber, Wermter. https://www.isca-speech.org/archive/Interspeech_2019/pdfs/2845.pdf

Data augmentation using variational autoencoder for embedding based speaker verification. Wu, Wang, Qian, Yu  https://zhanghaowu.me/assets/VAE_Data_Augmentation_proceeding.pdf

One-shot voice conversion with disentangled representations by leveraging phonetic posteriograms. Mohammadi, Kim. https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1798.pdf

EEG-based adaptive driver-vehicle interface using variational autoencoder and PI-TSVM.  Bi, Zhang, Lian https://www.researchgate.net/profile/Luzheng_Bi2/publication/335619300_EEG-Based_Adaptive_Driver-Vehicle_Interface_Using_Variational_Autoencoder_and_PI-TSVM/links/5d70bb234585151ee49e5a30/EEG-Based-Adaptive-Driver-Vehicle-Interface-Using-Variational-Autoencoder-and-PI-TSVM.pdf

Neural gaussian copula for variational autoencoder  Wang, Wang  https://arxiv.org/pdf/1909.03569.pdf

Enhancing VAEs for collaborative filtering: Flexible priors and gating mechanisms.  Kim, Suh  http://delivery.acm.org/10.1145/3350000/3347015/p403-kim.pdf?ip=86.162.136.199&id=3347015&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1568726810_89cfa7cbc7c1b0663405d4446f9fce85

Riemannian normalizing flow on variational wasserstein autoencoder for text modeling. Wang, Wang  https://arxiv.org/pdf/1904.02399.pdf

Disentanglement with hyperspherical latent spaces using diffusion variational autoencoders. Rey https://openreview.net/pdf?id=SylFDSU6Sr

Learning deep representations by mutual information estimation and maximization.  Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman, Trischler, Bengio https://arxiv.org/pdf/1808.06670.pdf  https://github.com/rdevon/DIM

Novel tracking approach based on fully-unsupervised disentanglement of the geometrical factors of variation.  Vladymyrov, Ariga https://arxiv.org/pdf/1909.04427.pdf

Real time trajectory prediction using conditional generative models.  Gomez-Gonzalez, Prokudin, Scholkopf, Peters https://arxiv.org/pdf/1909.03895.pdf

Disentanglement challenge: from regularization to reconstruction. Qiao, Li, Cai https://openreview.net/pdf?id=ByecPrUaHH

Improved disentanglement through aggregated convolutional feature maps. Seitzer https://openreview.net/pdf?id=ryxOvH86SH

Linked variational autoencoders for inferring substitutable and supplementary items.  Rakesh, Wang, Shu http://www.public.asu.edu/~skai2/files/wsdm_2019_lvae.pdf

On the fairness of disentangled representations.  Locatello, Abbati, Rainforth, Bauer, Scholkopf, Bachem  https://arxiv.org/pdf/1905.13662.pdf

Learning robust representations by projecting superficial statistics out. Wang, He, Lipton, Xing  https://openreview.net/pdf?id=rJEjjoR9K7

Understanding posterior collapse in generative latent variable models.  Lucas, Tucker, Grosse, Norouzi  https://openreview.net/pdf?id=r1xaVLUYuE

On the transfer of inductive bias from simulation to the real world: a new disentanglement dataset. Gondal, Wuthrich, Miladinovic, Locatello, Breidt, Volchkv, Akpo, Bachem, Scholkopf, Bauer https://arxiv.org/pdf/1906.03292.pdf  https://github.com/rr-learning/disentanglement_dataset

DIVA: domain invariant variational autoencoder. Ilse, Tomczak, Louizos, Welling https://arxiv.org/pdf/1905.10427.pdf  https://github.com/AMLab-Amsterdam/DIVA

Comment: Variational Autoencoders as empirical Bayes. Wang, Miller, Blei  http://www.stat.columbia.edu/~yixinwang/papers/WangMillerBlei2019.pdf 

Fast MVAE: joint separation and classification of mixed sources based on multichannel variational autoencoder with auxiliary classifier.  Li, Kameoka, Makino https://ieeexplore.ieee.org/abstract/document/8682623 

Reweighted expectation maximization.  Dieng, Paisley  https://arxiv.org/pdf/1906.05850.pdf  https://github.com/adjidieng/REM

Semisupervised text classification by variational autoencoder.  Xu, Tan https://ieeexplore.ieee.org/abstract/document/8672806 

Learning deep latent-variable MRFs with amortized Bethe free-energy minimization. Wiseman https://openreview.net/pdf?id=ByeMHULt_N

Contrastive variational autoencoder enhances salient features.  Abid, Zou https://arxiv.org/pdf/1902.04601.pdf  https://github.com/abidlabs/contrastive_vae

Learning latent superstructures in variational autoencoders for deep multidimensional clustering. Li, Chen, Poon, Zhang https://openreview.net/pdf?id=SJgNwi09Km


Tighter variational bounds are not necessarily better.  Rainforth, Kosiorek, Le, Maddison, Igl, Wood, The https://arxiv.org/pdf/1802.04537.pdf  https://github.com/lxuechen/DReG-PyTorch

ISA-VAE: Independent subspace analysis with variational autoencoders. Anon. https://openreview.net/pdf?id=rJl_NhR9K7


Manifold mixup: better representations by interpolating hidden states. Verma, Lamb, Beckham, Najafi, Mitliagkas, Courville, Lopez-Paz, Bengio. 
https://arxiv.org/pdf/1806.05236.pdf 
https://github.com/vikasverma1077/manifold_mixup

Bit-swap: recursive bits-back coding for lossless compression with hierarchical latent variables. Kingma, Abbeel, Ho. http://proceedings.mlr.press/v97/kingma19a/kingma19a.pdf 
https://github.com/fhkingma/bitswap

Practical lossless compression with latent variables using bits back coding.  Townsend, Bird, Barber. https://arxiv.org/pdf/1901.04866.pdf  https://github.com/bits-back/bits-back

BIVA:  a very deep hierarchy of latent variables for generative modeling. Maaloe, Fraccaro, Lievin, Winther.  https://arxiv.org/pdf/1902.02102.pdf

Flow++: improving flow-based generative models with variational dequantization and architecture design. Ho, Chen, Srinivas, Duan, Abbeel. https://arxiv.org/pdf/1902.00275.pdf  https://github.com/aravindsrinivas/flowpp

Sylvester normalizing flows for variational inference.  van den Berg, Hasenclever, Tomczak, Welling.  https://arxiv.org/pdf/1803.05649.pdf  https://github.com/riannevdberg/sylvester-flows

Unbiased implicit variational inference.  Titsias, Ruiz.  https://arxiv.org/pdf/1808.02078.pdf

Robustly disentangled causal mechanisms: validating deep representations for interventional robustness.   Suter, Miladinovic, Scholkopf, Bauer. https://arxiv.org/pdf/1811.00007.pdf

Tutorial: Deriving the standard variational autoencoder (VAE) loss function.  Odaibo  https://arxiv.org/pdf/1907.08956.pdf

Learning disentangled representations with reference-based variational autoencoders.  Ruiz, Martinez, Binefa, Verbeek.  https://arxiv.org/pdf/1901.08534

Disentangling factors of variation using few labels.  Locatello, Tschannen, Bauer, Ratsch, Scholkopf, Bachem  https://arxiv.org/pdf/1905.01258.pdf  

Disentangling disentanglement in variational autoencoders Mathieu, Rainforth, Siddharth, The, https://arxiv.org/pdf/1812.02833.pdf  https://github.com/iffsid/disentangling-disentanglement

LIA: latently invertible autoencoder with adversarial learning  Zhu, Zhao, Zhang  https://arxiv.org/pdf/1906.08090.pdf  

Emerging disentanglement in auto-encoder based unsupervised image content transfer. Press, Galanti, Benaim, Wolf  https://openreview.net/pdf?id=BylE1205Fm  https://github.com/oripress/ContentDisentanglement

MAE: Mutual posterior-divergence regularization for variational autoencoders  Ma, Zhou, Hovy  https://arxiv.org/pdf/1901.01498.pdf  https://github.com/XuezheMax/mae

Overcoming the disentanglement vs reconstruction trade-off via Jacobian supervision.  Lezama  https://openreview.net/pdf?id=Hkg4W2AcFm  https://github.com/jlezama/disentangling-jacobian https://github.com/jlezama/disentangling-jacobian/tree/master/unsupervised_disentangling

Challenging common assumptions in the unsupervised learning of disentangled representations.  Locatello, Bauer, Lucic, Ratsch, Gelly, Scholkopf, Bachem https://arxiv.org/abs/1811.12359  https://github.com/google-research/disentanglement_lib/blob/master/README.md

Variational prototyping encoder: one shot learning with prototypical images.  Kim, Oh, Lee, Pan, Kweon  http://openaccess.thecvf.com/content_CVPR_2019/papers/Kim_Variational_Prototyping-Encoder_One-Shot_Learning_With_Prototypical_Images_CVPR_2019_paper.pdf  

Diagnosing and enchanving VAE models (conf and journal paper both available). Dai, Wipf https://arxiv.org/pdf/1903.05789.pdf  https://github.com/daib13/TwoStageVAE

Disentangling latent hands for image synthesis and pose estimation. Yang, Yao http://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_Disentangling_Latent_Hands_for_Image_Synthesis_and_Pose_Estimation_CVPR_2019_paper.pdf 

Rare event detection using disentangled representation learning.  Hamaguchi, Sakurada, Nakamura http://openaccess.thecvf.com/content_CVPR_2019/papers/Hamaguchi_Rare_Event_Detection_Using_Disentangled_Representation_Learning_CVPR_2019_paper.pdf 

Disentangling latent space for VAE by label relevant/irrelvant dimensions.  Zheng, Sun  https://arxiv.org/pdf/1812.09502.pdf  https://github.com/ZhilZheng/Lr-LiVAE

Variational autoencoders pursue PCA directions (by accident). Rolinek, Zietlow, Martius https://arxiv.org/pdf/1812.06775.pdf  

Disentangled Representation learning for 3D face shape. Jiang, Wu, Chen, Zhang  https://arxiv.org/pdf/1902.09887.pdf  https://github.com/zihangJiang/DR-Learning-for-3D-Face

Preventing posterior collapse with delta-VAEs.  Razavi, van den Oord, Poole, Vinyals  https://arxiv.org/pdf/1901.03416.pdf  https://github.com/mattjj/svae

Gait recognition via disentangled representation learning.  Zhang, Tran, Yin, Atoum, Liu, Wan, Wang https://arxiv.org/pdf/1904.04925.pdf  

Hierarchical disentanglement of discriminative latent features for zero-shot learning.  Tong, Wang, Klinkigt, Kobayashi, Nonaka
http://openaccess.thecvf.com/content_CVPR_2019/papers/Tong_Hierarchical_Disentanglement_of_Discriminative_Latent_Features_for_Zero-Shot_Learning_CVPR_2019_paper.pdf  

Generalized zero- and few-shot learning via aligned variational autoencoders. Schonfeld, Ebrahimi, Sinha, Darrell, Akata  https://arxiv.org/pdf/1812.01784.pdf  https://github.com/chichilicious/Generalized-Zero-Shot-Learning-via-Aligned-Variational-Autoencoders

Unsupervised part-based disentangling of object shape and appearance. Lorenz, Bereska, Milbich, Ommer https://arxiv.org/pdf/1903.06946.pdf  

A semi-supervised Deep generative model for human body analysis.  de Bem, Ghosh, Ajanthan, Miksik, Siddaharth, Torr http://www.robots.ox.ac.uk/~tvg/publications/2018/W21P20.pdf

Multi-object representation learning with iterative variational inference.  Greff, Kaufman, Kabra, Watters, Burgess, Zoran, Matthey, Botvinick, Lerchner  https://arxiv.org/pdf/1903.00450.pdf  https://github.com/MichaelKevinKelly/IODINE

Generating diverse high-fidelity images with VQ-VAE-2.  Razavi, van den Oord, Vinyals https://arxiv.org/pdf/1906.00446.pdf  https://github.com/deepmind/sonnet/blob/master/sonnet/examples/vqvae_example.ipynb https://github.com/rosinality/vq-vae-2-pytorch


MONet: unsupervised scene decomposition and representation. Burgess, Matthey, Watters, Kabra, Higgins, Botvinick, Lerchner  https://arxiv.org/pdf/1901.11390.pdf  

Structured disentangled representations and Hierarchical disentangled representations.  Esmaeili, Wu, Jain, Bozkurt, Siddarth, Paige, Brooks, Dy, van de Meent  https://arxiv.org/pdf/1804.02086.pdf  

Spatial Broadcast Decoder: A  simple architecture for learning disentangled representations in VAEs.  Watters, Matthey, Burgess, Lerchner https://arxiv.org/pdf/1901.07017.pdf  https://github.com/lukaszbinden/spatial-broadcast-decoder

Resampled priors for variational autoencoders.  Bauer, Mnih https://arxiv.org/pdf/1802.06847.pdf

Weakly supervised disentanglement by pairwise similiarities.  Chen, Batmanghelich https://arxiv.org/pdf/1906.01044.pdf  

Deep variational information bottleneck.  Aelmi, Fischer, Dillon, Murphy  https://arxiv.org/pdf/1612.00410.pdf  https://github.com/alexalemi/vib_demo

Generalized variational inference.  Knoblauch, Jewson, Damoulas https://arxiv.org/pdf/1904.02063.pdf  

Variational autoencoders and nonlinear ICA: a unifying framework. Khemakhem, Kingma https://arxiv.org/pdf/1907.04809.pdf  

Lagging inference networks and posterior collapse in variational autoencoders.  He, Spokoyny, Neubig, Berg-Kirkpatrick  https://arxiv.org/pdf/1901.05534.pdf  https://github.com/jxhe/vae-lagging-encoder

Avoiding latent variable collapse with generative skip models.  Dieng, Kim, Rush, Blei  https://arxiv.org/pdf/1807.04863.pdf  

Distribution Matching in Variational inference. Rosca, Lakshminarayana, Mohamed https://arxiv.org/pdf/1802.06847.pdf  
A variational auto-encoder model for stochastic point process.  Mehrasa, Jyothi, Durand, He, Sigal, Mori  https://arxiv.org/pdf/1904.03273.pdf  

Sliced-Wasserstein auto-encoders. Kolouri, Pope, Martin, Rohde  https://openreview.net/pdf?id=H1xaJn05FQ  https://github.com/skolouri/swae

A deep generative model for graph layout. Kwon, Ma  https://arxiv.org/pdf/1904.12225.pdf  

Differentiable perturb-and-parse semi-supervised parsing with a structured variational autoencoder. Corro, Titov  https://openreview.net/pdf?id=BJlgNh0qKQ  https://github.com/FilippoC/diffdp

Variational autoencoders with jointly optimized latent dependency structure.  He, Gong, Marino, Mori, Lehrmann  https://openreview.net/pdf?id=SJgsCjCqt7  https://github.com/ys1998/vae-latent-structure

Unsupervised learning of spatiotemporally coherent metrics  Goroshin, Bruna, Tompson, Eigen, LeCun  https://arxiv.org/pdf/1412.6056.pdf

Temporal difference variational auto-encoder. Gregor, Papamakarios, Besse, Buesing, Weber https://arxiv.org/pdf/1806.03107.pdf  https://github.com/xqding/TD-VAE

Representation learning with contrastive predictive coding. van den Oord, Li, Vinyals https://arxiv.org/pdf/1807.03748.pdf  https://github.com/davidtellez/contrastive-predictive-coding

Representation disentanglement  for multi-task learning with application to fetal ultrasound  Meng, Pawlowski, Rueckert, Kainz  https://arxiv.org/pdf/1908.07885.pdf

M$2$VAE - derivation of a multi-modal variational autoencoder objective from the marginal joint log-likelihood. Korthals  https://arxiv.org/pdf/1903.07303.pdf

Predicting visual memory schemas with variational autoencoders. Kyle-Davidson, Bors, Evans  https://arxiv.org/pdf/1907.08514.pdf

T-CVAE: Transformer -based conditioned variational autoencoder for story completion.  Wang, Wan https://www.ijcai.org/proceedings/2019/0727.pdf https://github.com/sodawater/T-CVAE

PuVAE: A variational autoencoder to purify adversarial examples.  Hwang, Park, Jang, Yoon, Cho  https://arxiv.org/pdf/1903.00585.pdf

Coupled VAE: Improved accuracy and robustness of a variational autoencoder.   Cao, Li, Nelson https://arxiv.org/pdf/1906.00536.pdf

D-VAE: A variational autoencoder for directed acyclic graphs. Zhang, Jiang, Cui, Garnett, Chen  https://arxiv.org/abs/1904.11088  https://github.com/muhanzhang/D-VAE

Are disentangled representations helpful for abstract reasoning?  van Steenkiste, Locatello, Schmidhuber, Bachem  https://arxiv.org/pdf/1905.12506.pdf

A heuristic for unsupervised model selection for variational disentangled representation learning.  Duan, Watters, Matthey, Burgess, Lerchner, Higgins  https://arxiv.org/pdf/1905.12614.pdf

Dual space learning with variational autoencoders.  Okamoto, Suzuki, Higuchi, Ohsawa, Matsuo  https://pdfs.semanticscholar.org/ea70/6495d4a6214b3d6174bb7fd99c5a9c34c2e6.pdf

Variational autoencoders for sparse and overdispersed discrete data.  Zhao, Rai, Du, Buntine  https://arxiv.org/pdf/1905.00616.pdf

Variational auto-decoder. Zadeh, Lim, Liang, Morency. https://arxiv.org/pdf/1903.00840.pdf

Causal discovery with attention-based convolutional neural networks.  Naura, Bucur, Seifert   https://www.mdpi.com/2504-4990/1/1/19/pdf

Variational laplace autoencoders. Park, Kim, Kim  http://proceedings.mlr.press/v97/park19a/park19a.pdf

Variational autoencoders with normalizing flow decoders.    https://openreview.net/forum?id=r1eh30NFwB

Gaussian process priors for view-aware inference. Hou, Heljakka, Solin  https://arxiv.org/pdf/1912.03249.pdf

SGVAE: sequential graph variational autoencoder.  Jing, Chi, Tang https://arxiv.org/pdf/1912.07800.pdf  

improving multimodal generative models with disentangled latent partitions. Daunhawer, Sutter, Vogt http://bayesiandeeplearning.org/2019/papers/103.pdf 

Cross-population variational autoencoders.  Davison, Severson, Ghosh  https://openreview.net/pdf?id=r1eWdlBFwS http://bayesiandeeplearning.org/2019/papers/96.pdf 

Evidential disambiguation of latent multimodality in conditional variational autoencoders.  Itkina, Ivanovic, Senanayake, Kochenderfer, Pavone  http://bayesiandeeplearning.org/2019/papers/34.pdf  

Increasing the generalisation capacity of conditional VAEs. Klushyn, Chen, Cseke, Bayer, van der Smagt  https://link.springer.com/chapter/10.1007/978-3-030-30484-3_61  

Multi-source neural variational inference.  Kurle, Gunnemann, van der Smagt https://wvvw.aaai.org/ojs/index.php/AAAI/article/view/4311  

Early integration for movement modeling in latent spaces. Hornung, Chen, van der Smagt  https://books.google.co.uk/books?hl=en&lr=&id=M1WfDwAAQBAJ&oi=fnd&pg=PA305&dq=info:MRhvAh4qD7wJ:scholar.google.com&ots=hN84xN5saO&sig=TBMgkFo6z9wrL64TcvzjU4G5gCQ&redir_esc=y#v=onepage&q&f=false
  
Building face recognition system with triplet-based stacked variational denoising autoencoder.  LEe, Hart, Richens, Johri https://dl.acm.org/citation.cfm?id=3369707  

Cross-domain variational autoencoder for recommender systems. Shi, Wang  https://ieeexplore.ieee.org/abstract/document/8935901  
Predictive coding, variational autoencoders, and biological connections.  Marino  https://openreview.net/pdf?id=SyeumQYUUH  

A general and adaptive robust loss function Barron  https://arxiv.org/pdf/1701.03077.pdf  

Variational autoencoder trajectory primitives and discrete latent. Osa, Ikemoto https://arxiv.org/pdf/1912.04063.pdf  

Faster attend-infer-repeat with tractable probabilistic models. Stelzner, Peharz, Kersting  http://proceedings.mlr.press/v97/stelzner19a/stelzner19a.pdf  https://github/stelzner/supair

Learning predictive models from observation and interaction.  Schmeckpeper, Xie, Rybkin, Tian, Daniilidis, Levine, Finn https://arxiv.org/pdf/1912.12773.pdf

Translating visual art into music Muller-Eberstein, van Noord http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVFAD/Muller-Eberstein_Translating_Visual_Art_Into_Music_ICCVW_2019_paper.pdf

Non-parallel voice conversion with controllable speaker individuality using variational autoencoder.  Ho, Akagi  http://www.apsipa.org/proceedings/2019/pdfs/68.pdf

Derivation of the variational Bayes equations.  Maren https://arxiv.org/pdf/1906.08804.pdf


## 2018

DVAE++: Discrete variational autoencoders wth overlapping transformations.  Vahdat, Macready, Bian,Khoshaman, Andriyash http://proceedings.mlr.press/v80/vahdat18a/vahdat18a.pdf


FFJORD: free-form continuous dynamics for scalable reversible generative models.  Grathwohl, Chen, Bettencourt, Sutskever, Duvenaud https://arxiv.org/pdf/1810.01367.pdf

A general method for amortizing variational filtering.  Marino, Cvitkovic, Yue  https://arxiv.org/pdf/1811.05090.pdf  https://github.com/joelouismarino/amortized-variational-filtering

Handling incomplete heterogeneous data using VAEs.  Nazabal, Olmos, Ghahramani, Valera  https://arxiv.org/pdf/1807.03653.pdf  

Sequential attend, infer, repeat: generative modeling of moving objects.  Kosiorek, Kim, Posner, Teh  https://arxiv.org/pdf/1806.01794.pdf  https://github.com/akosiorek/sqair https://www.youtube.com/watch?v=-IUNQgSLE0c&feature=youtu.be

Doubly reparameterized gradient estimators for monte carlo objectives.  Tucker, Lawson, Gu, Maddison  https://arxiv.org/pdf/1810.04152.pdf

Interpretable intuitive physics model.  Ye, Wang, Davidson, Gupta https://arxiv.org/pdf/1808.10002.pdf  https://github.com/tianye95/interpretable-intuitive-physics-model

Normalizing Flows Tutorial, Part 2: Modern Normalizing Flows. Eric Jang https://blog.evjang.com/2018/01/nf2.html

Neural autoregressive flows.  Huang, Krueger, Lacoste, Courville  https://medium.com/element-ai-research-lab/neural-autoregressive-flows-f164d6b8e462 https://arxiv.org/pdf/1804.00779.pdf  https://github.com/CW-Huang/NAF

Gaussian process prior variational autoencoders.  Casale, Dalca, Sagletti, Listgarten, Fusi https://papers.nips.cc/paper/8238-gaussian-process-prior-variational-autoencoders.pdf

ACVAE-VC: non-parallel many-to-many voice conversion with auxiliary classifier variational autoencoder. Kameoka, Kaneko, Tanaka, Hojo https://arxiv.org/pdf/1808.05092.pdf

Discovering interpretable representations for both deep generative and discriminative models. Adel, Ghahramani, Weller  http://mlg.eng.cam.ac.uk/adrian/ICML18-Discovering.pdf

Autoregressive quantile networks for generative modelling . Ostrovski, Dabey, Munos  https://arxiv.org/pdf/1806.05575.pdf


Probabilistic video generation using holistic attribute control.  He, Lehrmann, Marino, Mori, Sigal https://arxiv.org/pdf/1803.08085.pdf

Bias and generalization in deep generative models: an empirical study.  Zhao, Ren, Yuan, Song, Goodman, Ermon https://arxiv.org/pdf/1811.03259.pdf  https://ermongroup.github.io/blog/bias-and-generalization-dgm/ https://github.com/ermongroup/BiasAndGeneralization/tree/master/Evaluate

On variational lower bounds of mutual information.  Poole, Ozair, van den Oord, Alemi, Tucker http://bayesiandeeplearning.org/2018/papers/136.pdf

GAN - why it is so hard to train generative adversarial networks  . Hui https://medium.com/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b

Counterfactuals uncover the modular structure of deep generative models.  Besserve, Sun, Scholkopf. https://arxiv.org/pdf/1812.03253.pdf

Learning independent causal mechanisms. Parascandolo, Kilbertus, Rojas-Carulla, Scholkopf https://arxiv.org/pdf/1712.00961.pdf

Emergence of invariance and disentanglement in deep representations.  Achille, Soatto https://arxiv.org/pdf/1706.01350.pdf

Variational memory encoder-decoder. Le, Tran, Nguyen, Venkatesh https://arxiv.org/pdf/1807.09950.pdf  https://github.com/thaihungle/VMED

Variational autoencoders for collaborative filtering. Liang, Krishnan, Hoffman, Jebara  https://arxiv.org/pdf/1802.05814.pdf

Invariant representations without adversarial training. Moyer, Gao, Brekelmans, Steeg, Galstyan http://papers.nips.cc/paper/8122-invariant-representations-without-adversarial-training.pdf https://github.com/dcmoyer/inv-rep

Density estimation: Variational autoencoders. Rui Shu http://ruishu.io/2018/03/14/vae/

TherML: The thermodynamics of machine learning. Alemi, Fishcer  https://arxiv.org/pdf/1807.04162.pdf

Leveraging the exact likelihood of deep latent variable models. Mattei, Frellsen  https://arxiv.org/pdf/1802.04826.pdf

What is wrong with VAEs?  Kosiorek  http://akosiorek.github.io/ml/2018/03/14/what_is_wrong_with_vaes.html 

Stochastic variational video prediction.  Babaeizadeh, Finn, Erhan, Campbell, Levine  https://arxiv.org/pdf/1710.11252.pdf  https://github.com/alexlee-gk/video_prediction

Variational attention for sequence-to-sequence models.  Bahuleyan, Mou, Vechtomova, Poupart https://arxiv.org/pdf/1712.08207.pdf  https://github.com/variational-attention/tf-var-attention

FactorVAE Disentangling by factorizing. Kim, Minh https://arxiv.org/pdf/1802.05983.pdf  

Disentangling factors of variation with cycle-consistent variational autoencoders.  Jha, Anand, Singh, Veeravasarapu  https://arxiv.org/pdf/1804.10469.pdf  https://github.com/ananyahjha93/cycle-consistent-vae

Isolating sources of disentanglement in VAEs. Chen, Li, Grosse, Duvenaud  https://arxiv.org/pdf/1802.04942.pdf

VAE with a VampPrior. Tomczak, Welling  https://arxiv.org/pdf/1705.07120.pdf  

A Framework for the quantitative evaluation of disentangled representations.  Eastwood, Williams  https://openreview.net/pdf?id=By-7dz-AZ https://github.com/cianeastwood/qedr

Recent advances in autoencoder based representation learning. Tschannen, Bachem, Lucic  https://arxiv.org/pdf/1812.05069.pdf  

InfoVAE: Balancing learning and inference in variational autoencoders.  Zhao, Song, Ermon https://arxiv.org/pdf/1706.02262.pdf  

Understanding disentangling in Beta-VAE.  Burgess, Higgins, Pal, Matthey, Watters, Desjardins, Lerchner https://arxiv.org/pdf/1804.03599.pdf  

Hidden Talents of the Variational autoencoder.  Dai, Wang, Aston, Hua, Wipf https://arxiv.org/pdf/1706.05148.pdf  

Variational Inference of disentangled latent concepts from unlabeled observations.  Kumar, Sattigeri, Balakrishnan  https://arxiv.org/abs/1711.00848  

Self-supervised learning of a facial attribute embedding from video.  Wiles, Koepke, Zisserman  http://www.robots.ox.ac.uk/~vgg/publications/2018/Wiles18a/wiles18a.pdf 

Wasserstein auto-encoders.  Tolstikhin, Bousquet, Gelly, Scholkopf  https://arxiv.org/pdf/1711.01558.pdf

A two-step disentanglement. method  Hadad, Wolf, Shahar
http://openaccess.thecvf.com/content_cvpr_2018/papers/Hadad_A_Two-Step_Disentanglement_CVPR_2018_paper.pdf  https://github.com/naamahadad/A-Two-Step-Disentanglement-Method

Taming VAEs.  Rezende, Viola  https://arxiv.org/pdf/1810.00597.pdf  https://github.com/denproc/Taming-VAEs https://github.com/syncrostone/Taming-VAEs

IntroVAE Introspective variational autoencoders for photographic image synthesis. Huang, Li, He, Sun, Tan https://arxiv.org/pdf/1807.06358.pdf  https://github.com/dragen1860/IntroVAE-Pytorch

Information constraints on auto-encoding variational bayes. Lopez, Regier, Jordan, Yosef  https://papers.nips.cc/paper/7850-information-constraints-on-auto-encoding-variational-bayes.pdf  https://github.com/romain-lopez/HCV

Learning disentangled joint continuous and discrete representations.  Dupont  https://papers.nips.cc/paper/7351-learning-disentangled-joint-continuous-and-discrete-representations.pdf https://github.com/Schlumberger/joint-vae

Neural discrete representation learning.  van den Oord, Vinyals, Kavukcuoglu  https://arxiv.org/pdf/1711.00937.pdf  https://github.com/1Konny/VQ-VAE  https://github.com/ritheshkumar95/pytorch-vqvae

Disentangled sequential autoencoder.  Li, Mandt https://arxiv.org/abs/1803.02991  https://github.com/yatindandi/Disentangled-Sequential-Autoencoder

Variational Inference: A review for statisticians.  Blei, Kucukelbir, McAuliffe https://arxiv.org/pdf/1601.00670.pdf  
Advances in Variational Inferece. Zhang, Kjellstrom https://arxiv.org/pdf/1711.05597.pdf  

Auto-encoding total correlation explanation.  Goa, Brekelmans, Steeg, Galstyan  https://arxiv.org/abs/1802.05822  Closest: https://github.com/gregversteeg/CorEx

Fixing a broken ELBO. Alemi, Poole, Fischer, Dillon, Saurous, Murphy  https://arxiv.org/pdf/1711.00464.pdf

The information autoencoding family: a lagrangian perspective on latent variable generative models. Zhao, Song, Ermon https://arxiv.org/pdf/1806.06514.pdf  https://github.com/ermongroup/lagvae

Debiasing evidence approximations: on importance-weighted autoencoders and jackknife variational inference. Nowozin https://openreview.net/pdf?id=HyZoi-WRb https://github.com/microsoft/jackknife-variational-inference

Unsupervised discrete sentence representation learning for interpretable neural dialog generation.  Zhao, Lee, Eskenazi https://vimeo.com/285802293 https://arxiv.org/pdf/1804.08069.pdf  https://github.com/snakeztc/NeuralDialog-LAED

Dual swap disentangling.  Feng, Wang, Ke, Zeng, Tao, Song https://papers.nips.cc/paper/7830-dual-swap-disentangling.pdf 

Multimodal generative models for scalable weakly-supervised learning. Wu, Goodman https://papers.nips.cc/paper/7801-multimodal-generative-models-for-scalable-weakly-supervised-learning.pdf  https://github.com/mhw32/multimodal-vae-public https://github.com/panpan2/Multimodal-Variational-Autoencoder

Do deep generative models know what they don't know?  Nalisnick, Matsukawa, The, Gorur, Lakshminarayanan  https://arxiv.org/pdf/1810.09136.pdf  

Glow: generative flow with invertible 1x1 convolutions. Kingma, Dhariwal  https://arxiv.org/pdf/1807.03039.pdf  https://github.com/openai/glow https://github.com/pytorch/glow

Inference suboptimality in variational autoencoders.  Cremer, Li, Duvenaud  https://arxiv.org/pdf/1801.03558.pdf  https://github.com/chriscremer/Inference-Suboptimality

Adversarial Variational Bayes: unifying variational autoencoders and generative adversarial networks. Mescheder, Mowozin, Geiger  https://arxiv.org/pdf/1701.04722.pdf  https://github.com/LMescheder/AdversarialVariationalBayes

Semi-amortized variational autoencoders.  Kim, Wiseman, Miller, Sontag, Rush  https://arxiv.org/pdf/1802.02550.pdf  https://github.com/harvardnlp/sa-vae

Spherical Latent Spaces for stable variational autoencoders.  Xu, Durrett https://arxiv.org/pdf/1808.10805.pdf  https://github.com/jiacheng-xu/vmf_vae_nlp

Hyperspherical variational auto-encoders. Davidson, Falorsi, De Cao, Kipf, Tomczak  https://arxiv.org/pdf/1804.00891.pdf  https://github.com/nicola-decao/s-vae-tf https://github.com/nicola-decao/s-vae-pytorch

Fader networks: manipulating images by sliding attributes.  Lample, Zeghidour, Usunier, Bordes, Denoyer, Ranzato  https://arxiv.org/pdf/1706.00409.pdf  https://github.com/facebookresearch/FaderNetworks

Training VAEs under structured residuals. Dorta, Vicente, Agapito, Campbell, Prince, Simpson  https://arxiv.org/pdf/1804.01050.pdf  https://github.com/Garoe/tf_mvg

oi-VAE: output interpretable VAEs for nonlinear group factor analysis.  Ainsworth, Foti, Lee, Fox https://arxiv.org/pdf/1802.06765.pdf  https://github.com/samuela/oi-vae

infoCatVAE: representation learning with categorical variational autoencoders.  Lelarge, Pineau https://arxiv.org/pdf/1806.08240.pdf  https://github.com/edouardpineau/infoCatVAE

Iterative Amortized inference.  Marino, Yue, Mandt  https://arxiv.org/pdf/1807.09356.pdf https://vimeo.com/287766880  https://github.com/joelouismarino/iterative_inference

On unifying Deep Generative Models. Hu, Yang, Salakhutdinov, Xing https://arxiv.org/pdf/1706.00550.pdf  

Diverse Image-to-image translation via disentangled representations.  Lee, Tseng, Huang, Singh, Yang  https://arxiv.org/pdf/1808.00948.pdf  https://github.com/HsinYingLee/DRIT

PIONEER networks: progressively growing generative autoencoder. Heljakka, Solin, Kannala  https://arxiv.org/pdf/1807.03026.pdf  https://github.com/AaltoVision/pioneer

Towards a definition of disentangled representations. Higgins, Amos, Pfau, Racaniere, Matthey, Rezende, Lerchner  https://arxiv.org/pdf/1812.02230.pdf  

Life-long disentangled representation learning with cross-domain latent homologies. Achille, Eccles, Matthey, Burgess, Watters, Lerchner,  Higgins  file:///Users/matthewvowels/Downloads/Life-Long_Disentangled_Representation_Learning_wit.pdf  

Learning deep disentangled embeddings with F-statistic loss.  Ridgeway, Mozer https://arxiv.org/pdf/1802.05312.pdf  https://github.com/kridgeway/f-statistic-loss-nips-2018

Learning latent subspaces in variational  autoencoders. Klys, Snell, Zemel  https://arxiv.org/pdf/1812.06190.pdf

On the latent space of Wasserstein auto-encoders. Rubenstein, Scholkopf, Tolstikhin.  https://arxiv.org/pdf/1802.03761.pdf  https://github.com/tolstikhin/wae

Learning disentangled representations with Wasserstein auto-encoders. Rubenstein, Scholkopf, Tolstikhin https://openreview.net/pdf?id=Hy79-UJPM 

The mutual autoencoder: controlling information in latent code representations. Phuong, Kushman, Nowozin, Tomioka, Welling  https://openreview.net/pdf?id=HkbmWqxCZ   https://openreview.net/pdf?id=HkbmWqxCZ http://2017.ds3-datascience-polytechnique.fr/wp-content/uploads/2017/08/DS3_posterID_048.pdf  

Auxiliary guided autoregressive variational autoencoders. Lucas, Verkbeek https://openreview.net/pdf?id=HkGcX--0- https://github.com/pclucas14/aux-vae

Interventional robustness of deep latent variable models. Suter, Miladinovic, Bauer, Scholkopf  https://pdfs.semanticscholar.org/8028/a56d6f9d2179416d86837b447c6310bd371d.pdf?_ga=2.190184363.1450484303.1564569882-397935340.1548854421 

Understanding degeneracies and ambiguities in attribute transfer. Szabo, Hu, Portenier, Zwicker, Facaro http://openaccess.thecvf.com/content_ECCV_2018/papers/Attila_Szabo_Understanding_Degeneracies_and_ECCV_2018_paper.pdf 
DNA-GAN: learning disentangled representations from multi-attribute images.
Xiao, Hong, Ma  https://arxiv.org/pdf/1711.05415.pdf  https://github.com/Prinsphield/DNA-GAN

Normalizing flows.  Kosiorek  http://akosiorek.github.io/ml/2018/04/03/norm_flows.html  

Hamiltonian variational auto-encoder  Caterini, Doucet, Sejdinovic  https://arxiv.org/pdf/1805.11328.pdf  

Causal generative neural networks.  Goudet, Kalainathan, Caillou, Guyon, Lopez-Paz, Sebag.  https://arxiv.org/pdf/1711.08936.pdf  https://github.com/GoudetOlivier/CGNN

Flow-GAN: Combining maximum likelihood and adversarial learning in generative models. Grover, Dhar, Ermon https://arxiv.org/pdf/1705.08868.pdf  https://github.com/ermongroup/flow-gan

Linked causal variational autoencoder for inferring paired spillover effects. Rakesh, Guo, Moraffah, Agarwal, Liu https://arxiv.org/pdf/1808.03333.pdf  https://github.com/rguo12/CIKM18-LCVA

Unsupervised anomaly detection via variational auto-encoder for seasonal KPIs in web applications.  Xu, Chen, Zhao, Li, Bu, Li, Liu, Zhao, Pei, Feng, Chen, Wang, Qiao  https://arxiv.org/pdf/1802.03903.pdf

Mutual information neural estimation. Belghazi, Baratin, Rajeswar, Ozair, Bengio, Hjelm.  https://arxiv.org/pdf/1801.04062.pdf  https://github.com/sungyubkim/MINE-Mutual-Information-Neural-Estimation- https://github.com/mzgubic/MINE

Explorations in homeomorphic variational auto-encoding. Falorsi, de Haan, Davidson, Cao, Weiler, Forre, Cohen.  https://arxiv.org/pdf/1807.04689.pdf  https://github.com/pimdh/lie-vae

Hierarchical variational memory network for dialogue generation.  Chen, Ren, Tang, Zhao, Yin  http://delivery.acm.org/10.1145/3190000/3186077/p1653-chen.pdf?ip=86.162.136.199&id=3186077&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1569938843_c07ad21d173fc64a44a22fd6521140cb

World models. Ha, Schmidhuber https://arxiv.org/pdf/1803.10122.pdf

## 2017

The concrete distribution: a continuous relaxation of discrete random variables.  Maddison, Mnih, The https://arxiv.org/pdf/1611.00712.pdf

Categorical reparameterization with Gumbel-Softmax. Jang, Gu, Poole https://arxiv.org/abs/1611.01144

Opening the black box of deep neural networks via information.  Schwartz-Ziv, Tishby  https://arxiv.org/pdf/1703.00810.pdf  https://www.youtube.com/watch?v=gOn8Po_NPe4


Discovering causal signals in images  . Lopez-Paz, Nishihara, Chintala, Scholkopf, Bottou   https://arxiv.org/pdf/1605.08179.pdf

Autoencoding variational inference for topic models.  Srivastava, Sutton  https://arxiv.org/pdf/1703.01488.pdf

Hidden Markov model variational autoencoder for acoustic unit discovery.  Ebbers, Heymann, Drude, Glarner, Haeb-Umbach, Raj https://www.isca-speech.org/archive/Interspeech_2017/pdfs/1160.PDF

Application of variational autoencoders for aircraft turbomachinery design.   Zalger  http://cs229.stanford.edu/proj2017/final-reports/5231979.pdf

Semi-supervised learning with variational autoencoders. Keng   http://bjlkeng.github.io/posts/semi-supervised-learning-with-variational-autoencoders/

Causal effect inference with deep latent variable models. Louizos, Shalit, Mooij, Sontag, Zemel, Welling  https://arxiv.org/pdf/1705.08821.pdf  https://github.com/AMLab-Amsterdam/CEVAE

beta-VAE: learning basic visual concepts with a constrained variational framework.  Higgins, Matthey, Pal, Burgess, Glorot, Botvinick, Mohamed, Lerchner  https://openreview.net/pdf?id=Sy2fzU9gl 

Challenges in disentangling independent factors of variation. Szabo, Hu, Portenier, Facaro, Zwicker https://arxiv.org/pdf/1711.02245.pdf  https://github.com/ananyahjha93/challenges-in-disentangling

Composing graphical models with neural networks for structured representations and fast inference.  Johnson, Duvenaud, Wiltschko, Datta, Adams  https://arxiv.org/pdf/1603.06277.pdf  

Split-brain autoencoders: unsupervised learning by cross-channel prediction.  Zhang, Isola, Efros https://arxiv.org/pdf/1611.09842.pdf  

Learning disentangled representations with semi-supervised deep generative models.Siddharth, Paige, van de Meent, Desmaison, Goodman, Kohli, Wood, Torr https://papers.nips.cc/paper/7174-learning-disentangled-representations-with-semi-supervised-deep-generative-models.pdf https://github.com/probtorch/probtorch

Learning hierarchical features from generative models.  Zhao, Song, Ermon https://arxiv.org/pdf/1702.08396.pdf  https://github.com/ermongroup/Variational-Ladder-Autoencoder

Multi-level variational autoencoder: learning disentangled representations from grouped observations. Bouchacourt, Tomioka, Nowozin https://arxiv.org/pdf/1705.08841.pdf  

Neural Face editing with intrinsic image disentangling. Shu, Yumer, Hadap, Sankavalli, Shechtman, Samaras http://openaccess.thecvf.com/content_cvpr_2017/papers/Shu_Neural_Face_Editing_CVPR_2017_paper.pdf https://github.com/zhixinshu/NeuralFaceEditing

Variational Lossy Autoencoder.  Chen, Kingma, Salimans, Duan, Dhariwal, Schulman, Sutskever, Abbeel https://arxiv.org/abs/1611.02731  https://github.com/jiamings/tsong.me/blob/master/_posts/reading/2016-11-08-lossy-vae.md

Unsupervised learning of disentangled and interpretable representations from sequential data. Hsu, Zhang, Glass https://papers.nips.cc/paper/6784-unsupervised-learning-of-disentangled-and-interpretable-representations-from-sequential-data.pdf  https://github.com/wnhsu/FactorizedHierarchicalVAE https://github.com/wnhsu/ScalableFHVAE

Factorized variational autoencoder for modeling audience reactions to movies. Deng, Navarathna, Carr, Mandt, Yue, Matthews, Mori  http://www.yisongyue.com/publications/cvpr2017_fvae.pdf 

Learning latent representations for speech generation and transformation. Hsu, Zhang, Glass https://arxiv.org/pdf/1704.04222.pdf  https://github.com/wnhsu/SpeechVAE

Unsupervised learning of disentangled representations from video. Denton, Birodkar  https://papers.nips.cc/paper/7028-unsupervised-learning-of-disentangled-representations-from-video.pdf  https://github.com/ap229997/DRNET

Laplacian pyramid of conditional variational autoencoders.  Dorta, Vicente, Agapito, Campbell, Prince, Simpson  http://cs.bath.ac.uk/~nc537/papers/cvmp17_LapCVAE.pdf 

Neural Photo Editing with Inrospective Adverarial Networks. Brock, Lim, Ritchie, Weston https://arxiv.org/pdf/1609.07093.pdf  https://github.com/ajbrock/Neural-Photo-Editor

Discrete Variational Autoencoder. Rolfe https://arxiv.org/pdf/1609.02200.pdf  https://github.com/QuadrantAI/dvae

Reinterpreting importance-weighted autoencoders.  Cremer, Morris, Duvenaud  https://arxiv.org/pdf/1704.02916.pdf  https://github.com/FighterLYL/iwae

Density Estimation using realNVP. Dinh, Sohl-Dickstein, Bengio  https://arxiv.org/pdf/1605.08803.pdf  https://github.com/taesungp/real-nvp https://github.com/chrischute/real-nvp

JADE: Joint autoencoders for disentanglement. Banijamali, Karimi, Wong, Ghosi https://arxiv.org/pdf/1711.09163.pdf  
Joint Multimodal learning with deep generative models.  Suzuki, Nakayama, Matsuo  https://openreview.net/pdf?id=BkL7bONFe https://github.com/masa-su/jmvae

Towards a deeper understanding of variational autoencoding models.  Zhao, Song, Ermon https://arxiv.org/pdf/1702.08658.pdf  https://github.com/ermongroup/Sequential-Variational-Autoencoder

Lagging inference networks and posterior collapse in variational autoencoders.  Dilokthanakul, Mediano, Garnelo, Lee, Salimbeni, Arulkumaran, Shanahan  https://arxiv.org/pdf/1611.02648.pdf  https://github.com/Nat-D/GMVAE https://github.com/psanch21/VAE-GMVAE

On the challenges of learning with inference networks on sparse, high-dimensional data. Krishnan, Liang, Hoffman  https://arxiv.org/pdf/1710.06085.pdf  https://github.com/rahulk90/vae_sparse

Stick-breaking Variational Autoencoder.   https://arxiv.org/pdf/1605.06197.pdf  https://github.com/sporsho/hdp-vae

Deep variational canonical correlation analysis.  Wang, Yan, Lee, Livescu https://arxiv.org/pdf/1610.03454.pdf  https://github.com/edchengg/VCCA_pytorch

Nonparametric variational auto-encoders for hierarchical representation learning. Goyal, Hu, Liang, Wang, Xing  https://arxiv.org/pdf/1703.07027.pdf  https://github.com/bobchennan/VAE_NBP/blob/master/report.markdown

PixelSNAIL: An improved autoregressive generative model.  Chen, Mishra, Rohaninejad, Abbeel https://arxiv.org/pdf/1712.09763.pdf  https://github.com/neocxi/pixelsnail-public

Improved Variational Inference with inverse autoregressive flows. Kingma, Salimans, Jozefowicz, Chen, Sutskever, Welling  https://arxiv.org/pdf/1606.04934.pdf  https://github.com/kefirski/bdir_vae

It takes (only) two: adversarial generator-encoder networks.  Ulyanov, Vedaldi, Lempitsky https://arxiv.org/pdf/1704.02304.pdf  https://github.com/DmitryUlyanov/AGE

Symmetric Variational Autoencoder and connections to adversarial learning.  Chen, Dai, Pu, Li, Su, Carin  https://arxiv.org/pdf/1709.01846.pdf  

Reconstruction-based disentanglement for pose-invariant face recognition. Peng, Yu, Sohn, Metaxas, Chandraker https://arxiv.org/pdf/1702.03041.pdf  https://github.com/zhangjunh/DR-GAN-by-pytorch

Is maximum likelihood useful for representation learning? Huszár  https://www.inference.vc/maximum-likelihood-for-representation-learning-2/  

Disentangled representation learning GAN for pose-invariant face recognition. Tran, Yin, Liu  http://zpascal.net/cvpr2017/Tran_Disentangled_Representation_Learning_CVPR_2017_paper.pdf https://github.com/kayamin/DR-GAN

Improved Variational Autoencoders for text modeling using dilated convolutions. Yang, Hu, Salakhutdinov, Berg-kirkpatrick https://arxiv.org/pdf/1702.08139.pdf  

Improving variational auto-encoders using householder flow. Tomczak, Welling  https://arxiv.org/pdf/1611.09630.pdf  https://github.com/jmtomczak/vae_householder_flow

Sticking the landing: simple, lower-variance gradient estimators for variational inference. Roeder, Wu, Duvenaud. http://proceedings.mlr.press/v97/kingma19a/kingma19a.pdf  https://github.com/geoffroeder/iwae

VEEGAN: Reducing mode collapse in GANs using implicit variational learning. Srivastava, Valkov, Russell, Gutmann. https://arxiv.org/pdf/1705.07761.pdf  https://github.com/akashgit/VEEGAN

Discovering discrete latent topics with neural variational inference. Miao, Grefenstette, Blunsom https://arxiv.org/pdf/1706.00359.pdf

Variational approaches for auto-encoding generative adversarial networks.   Rosca, Lakshminarayana, Warde-Farley, Mohamed https://arxiv.org/pdf/1706.04987.pdf

Variational Autoencoder and extensions. Courville https://ift6266h17.files.wordpress.com/2017/03/vae1.pdf

A neural representation of sketch drawings. Ha, Eck https://arxiv.org/pdf/1704.03477.pdf

## 2016

Attend, infer, repeat: fast scene understanding with generative models. Eslami, Heess, Weber, Tassa, Szepesvari, Kavukcuoglu, Hinton  https://arxiv.org/pdf/1603.08575.pdf  http://akosiorek.github.io/ml/2017/09/03/implementing-air.html https://github.com/aleju/papers/blob/master/neural-nets/Attend_Infer_Repeat.md

Deep feature consistent variational autoencoder.  Hou, Shen, Sun, Qiu https://arxiv.org/pdf/1610.00291.pdf  https://github.com/sbavon/Deep-Feature-Consistent-Variational-AutoEncoder-in-Tensorflow

Neural variational inference for text processing.   Miao, Yu, Grefenstette,  Blunsom. https://arxiv.org/pdf/1511.06038.pdf

Domain-adversarial training of neural networks. Ganin, Ustinova, Ajakan, Germain, Larochelle, Laviolette, Marchand, Lempitsky https://arxiv.org/pdf/1505.07818.pdf

Tutorial on Variational Autoencoders. Doersch https://arxiv.org/pdf/1606.05908.pdf

How to train deep variational autoencoders and probabilistic ladder networks. Sonderby, Raiko, Maaloe, Sonderby, Winther  https://orbit.dtu.dk/files/121765928/1602.02282.pdf 

ELBO surgery: yet another way to carve up the variational evidence lower bound. Hoffman, Johnson  http://approximateinference.org/accepted/HoffmanJohnson2016.pdf 

Variational inference with normalizing flows. Rezende, Mohamed  https://arxiv.org/pdf/1505.05770.pdf  

The Variational Fair Autoencoder. Louizos, Swersky, Li, Welling, Zemel  https://arxiv.org/pdf/1511.00830.pdf  https://github.com/dendisuhubdy/vfae

Information dropout: learning optimal representations through noisy computations. Achille, Soatto https://arxiv.org/pdf/1611.01353.pdf  

Domain separation networks. Bousmalis, Trigeorgis, Silberman, Krishnan, Erhan https://arxiv.org/pdf/1608.06019.pdf  https://github.com/fungtion/DSN  https://github.com/farnazj/Domain-Separation-Networks

Disentangling factors of variation in deep representations using adversarial training.  Mathieu, Zhao, Sprechmann, Ramesh, LeCunn https://arxiv.org/pdf/1611.03383.pdf  https://github.com/ananyahjha93/disentangling-factors-of-variation-using-adversarial-training

Variational autoencoder for semi-supervised text classification.  Xu, Sun, Deng, Tan  https://arxiv.org/pdf/1603.02514.pdf  https://github.com/wead-hsu/ssvae related: https://github.com/isohrab/semi-supervised-text-classification

Learning what and where to draw.  Reed, Sohn, Zhang, Lee  https://arxiv.org/pdf/1610.02454.pdf  

Attribute2Image: Conditional image generation from visual attributes. Yan, Yang, Sohn, Lee  https://arxiv.org/pdf/1512.00570.pdf  

Variational inference with normalizing flows. Rezende, Mohamed  https://arxiv.org/pdf/1505.05770.pdf  https://github.com/ex4sperans/variational-inference-with-normalizing-flows

Wild Variational Approximations.  Li, Liu http://approximateinference.org/2016/accepted/LiLiu2016.pdf 

Importance Weighted Autoencoders. Burda,  Grosse, Salakhutdinov https://arxiv.org/pdf/1509.00519.pdf  https://github.com/yburda/iwae https://github.com/xqding/Importance_Weighted_Autoencoders
https://github.com/abdulfatir/IWAE-tensorflow

Stacked What-Where Auto-encoders. Zhao, Mathieu, Goroshin, LeCunn https://arxiv.org/pdf/1506.02351.pdf  https://github.com/yselivonchyk/Tensorflow_WhatWhereAutoencoder

Disentangling nonlinear perceptual embeddings with multi-query triplet networks.  Veit, Belongie, Karaletsos  https://www.researchgate.net/profile/Andreas_Veit/publication/301837223_Disentangling_Nonlinear_Perceptual_Embeddings_With_Multi-Query_Triplet_Networks/links/57e2997308ae040ae3c2f3a3/Disentangling-Nonlinear-Perceptual-Embeddings-With-Multi-Query-Triplet-Networks.pdf  

Ladder Variational Autoencoders.  Sonderby, Raiko, Maaloe, Sonderby, Winther  https://arxiv.org/pdf/1602.02282.pdf  
Variational autoencoder for deep learning of images, labels and captions. Pu, Gan Henao, Yuan, Li, Stevens, Carin https://papers.nips.cc/paper/6528-variational-autoencoder-for-deep-learning-of-images-labels-and-captions.pdf 

Approximate inference for deep latent Gaussian mixtures.  Nalisnick, Hertel, Smyth  https://pdfs.semanticscholar.org/f6fe/5e8e25994c188ba6a124462e2cc55f2c5a67.pdf  https://github.com/enalisnick/mixture_density_VAEs

Auxiliary Deep Generative Models. Maaloe, Sonderby, Sonderby, Winther https://arxiv.org/pdf/1602.05473.pdf  https://github.com/larsmaaloee/auxiliary-deep-generative-models

Variational methods for conditional multimodal deep learning. Pandey, Dukkipati https://arxiv.org/pdf/1603.01801.pdf  

PixelVAE: a latent variable model for natural images. Gulrajani, Kumar, Ahmed, Taiga, Visin, Vazquez, Courville https://arxiv.org/pdf/1611.05013.pdf  https://github.com/igul222/PixelVAE https://github.com/kundan2510/pixelVAE

Adversarial autoencoders. Makhzani, Shlens, Jaitly, Goodfellow, Frey  https://arxiv.org/pdf/1511.05644.pdf  https://github.com/conan7882/adversarial-autoencoders

A hierarchical latent variable encoder-decoder model for generating dialogues.  Serban, Sordoni, Lowe, Charlin, Pineau, Courville, Bengio http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf 

Infinite variational autoencoder for semi-supervised learning.  Abbasnejad, Dick  https://arxiv.org/pdf/1611.07800.pdf  

f-GAN: Training generative neural samplers using variational divergence minimization. Nowozin, Cseke  https://arxiv.org/pdf/1606.00709.pdf  https://github.com/LynnHo/f-GAN-Tensorflow

DISCO Nets: DISsimilarity Coefficient networks  Bouchacourt, Kumar, Nowozin https://arxiv.org/pdf/1606.02556.pdf  https://github.com/oval-group/DISCONets

Information dropout: learning optimal representations through noisy computations. Achille, Soatto https://arxiv.org/pdf/1611.01353.pdf

Weakly-supervised disentangling with recurrent transformations for 3D view synthesis. Yang, Reed, Yang, Lee https://arxiv.org/pdf/1601.00706.pdf  https://github.com/jimeiyang/deepRotator

Autoencoding beyond pixels using a learned similarity metric. Boesen, Larsen, Sonderby, Larochelle, Winther https://arxiv.org/pdf/1512.09300.pdf  https://github.com/andersbll/autoencoding_beyond_pixels

Generating images with perceptual similarity metrics based on deep networks Dosovitskiy, Brox.  https://arxiv.org/pdf/1602.02644.pdf  https://github.com/shijx12/DeepSim

A note on the evaluation of generative models.  Theis, van den Oord, Bethge.  https://arxiv.org/pdf/1511.01844.pdf

InfoGAN: interpretable representation learning by information maximizing generative adversarial nets. Chen, Duan, Houthooft, Schulman, Sutskever, Abbeel  https://arxiv.org/pdf/1606.03657.pdf  https://github.com/openai/InfoGAN

Disentangled representations in neural models.  Whitney https://arxiv.org/abs/1602.02383

A recurrent latent variable model for sequential data.  Chung, Kastner, Dinh, Goel, Courville, Bengio https://arxiv.org/pdf/1506.02216.pdf

Unsupervised learning of 3D structure from images.  Rezende, Eslami, Mohamed, Battaglia, Jaderberg, Heess https://arxiv.org/pdf/1607.00662.pdf

A survey of inductive biases for factorial representation-learning. Ridgeway  https://arxiv.org/pdf/1612.05299.pdf


## 2015
Deep learning and the information bottleneck principle  Tishby, Zaslavsky https://arxiv.org/pdf/1503.02406.pdf

Training generative neural networks via Maximum Mean Discrepancy optimization.  Dziugaite, Roy, Ghahramani  https://arxiv.org/pdf/1505.03906.pdf


NICE: non-linear independent components estimation. Dinh, Krueger, Bengio https://arxiv.org/pdf/1410.8516.pdf 

Deep convolutional inverse graphics network.  Kulkarni, Whitney, Kohli, Tenenbaum https://arxiv.org/pdf/1503.03167.pdf  https://github.com/yselivonchyk/TensorFlow_DCIGN

Learning structured output representation using deep conditional generative models. Sohn, Yan, Lee  https://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf  https://github.com/wsjeon/ConditionalVariationalAutoencoder

Latent variable model with diversity-inducing mutual angular regularization.  Xie, Deng, Xing https://arxiv.org/pdf/1512.07336.pdf

DRAW: a recurrent neural network for image generation.  Gregor, Danihelka, Graves, Rezende, Wierstra. https://arxiv.org/pdf/1502.04623.pdf  https://github.com/ericjang/draw

Variational Inference II. Xing, Zheng, Hu, Deng https://www.cs.cmu.edu/~epxing/Class/10708-15/notes/10708_scribe_lecture13.pdf  

## 2014

Auto-encoding variational Bayes.  Kingma, Welling https://arxiv.org/pdf/1312.6114.pdf

Learning to disentangle factors of variation with manifold interaction. Reed, Sohn, Zhang, Lee  http://proceedings.mlr.press/v32/reed14.pdf 

Semi-supervised learning with deep generative models. Kingma, Rezende, Mohamed, Welling https://papers.nips.cc/paper/5352-semi-supervised-learning-with-deep-generative-models.pdf  https://github.com/saemundsson/semisupervised_vae https://github.com/Response777/Semi-supervised-VAE

Stochastic backpropagation and approximate inference in deep generative models. Rezende, Mohamed, Wierstra  https://arxiv.org/pdf/1401.4082.pdf https://github.com/ashwindcruz/dgm/tree/master/adgm_mnist

Representation learning: a review and new perspectives. Bengio, Courville, Vincent  https://arxiv.org/pdf/1206.5538.pdf

## 2011
Transforming Auto-encoders. Hinton, Krizhevsky, Wang  https://www.cs.toronto.edu/~hinton/absps/transauto6.pdf 


## 2008

Graphical models, exponential families, and variational inference.  Wainwright, Jordan et al

## 2004

Variational learning and bits-back coding: an information-theoretic view to Bayesian learning.  Honkela, Valpola  https://www.cs.helsinki.fi/u/ahonkela/papers/infview.pdf  

## 2000

The information bottleneck method.  Tishby, Pereira, Bialek https://arxiv.org/pdf/physics/0004057.pdf
